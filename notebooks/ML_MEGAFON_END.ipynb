{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fc8a7fb",
   "metadata": {},
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ddeb296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ea354e",
   "metadata": {},
   "source": [
    "pip install -U scikit-learn==1.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b55ddbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit, cross_val_score, learning_curve\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score,\\\n",
    "        recall_score, classification_report, precision_recall_curve,\\\n",
    "        confusion_matrix, auc, roc_curve\n",
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e268fc36",
   "metadata": {},
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81513f4d",
   "metadata": {},
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a385ac",
   "metadata": {},
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bde25ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm\n",
    "import  catboost as catb\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d5c31a",
   "metadata": {},
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ae7ee75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c5b4d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_report(y_train_true, y_train_pred, y_test_true, y_test_pred):\n",
    "    print('TRAIN\\n\\n' + classification_report(y_train_true, y_train_pred))\n",
    "    print('TEST\\n\\n' + classification_report(y_test_true, y_test_pred))\n",
    "    print('CONFUSION MATRIX\\n')\n",
    "    print(pd.crosstab(y_test_true, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4c9ab53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_preds(model, X_train, X_test, y_train, y_test):\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    get_classification_report(y_train, y_train_pred, y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "035b5725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_df_by_target_advance(df, target_name, method='over'):\n",
    "\n",
    "    assert method in ['over', 'under', 'tomek', 'smote'], 'Неверный метод сэмплирования'\n",
    "    \n",
    "    target_counts = df[target_name].value_counts()\n",
    "\n",
    "    major_class_name = target_counts.argmax()\n",
    "    minor_class_name = target_counts.argmin()\n",
    "\n",
    "    disbalance_coeff = int(target_counts[major_class_name] / target_counts[minor_class_name]) - 1\n",
    "    if method == 'over':\n",
    "        for i in range(disbalance_coeff):\n",
    "            sample = df[df[target_name] == minor_class_name].sample(target_counts[minor_class_name])\n",
    "            df = df.append(sample, ignore_index=True)\n",
    "            \n",
    "    elif method == 'under':\n",
    "        df_ = df.copy()\n",
    "        df = df_[df_[target_name] == minor_class_name]\n",
    "        tmp = df_[df_[target_name] == major_class_name]\n",
    "        df = df.append(tmp.iloc[\n",
    "            np.random.randint(0, tmp.shape[0], target_counts[minor_class_name])\n",
    "        ], ignore_index=True)\n",
    "\n",
    "    elif method == 'tomek':\n",
    "        from imblearn.under_sampling import TomekLinks\n",
    "        tl = TomekLinks()\n",
    "        X_tomek, y_tomek = tl.fit_resample(df.drop(columns=target_name), df[target_name])\n",
    "        df = pd.concat([X_tomek, y_tomek], axis=1)\n",
    "    \n",
    "    elif method == 'smote':\n",
    "        from imblearn.over_sampling import SMOTE\n",
    "        smote = SMOTE()\n",
    "        X_smote, y_smote = smote.fit_resample(df.drop(columns=target_name), df[target_name])\n",
    "        df = pd.concat([X_smote, y_smote], axis=1)\n",
    "\n",
    "    return df.sample(frac=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "610ee374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_feature_importances(feature_names, feature_importances, get_top=None):\n",
    "    feature_importances = pd.DataFrame({'feature': feature_names, 'importance': feature_importances})\n",
    "    feature_importances = feature_importances.sort_values('importance', ascending=False)\n",
    "       \n",
    "    plt.figure(figsize = (20, len(feature_importances) * 0.355))\n",
    "    \n",
    "    sns.barplot(feature_importances['importance'], feature_importances['feature'])\n",
    "    \n",
    "    plt.xlabel('Importance')\n",
    "    plt.title('Importance of features')\n",
    "    plt.show()\n",
    "    \n",
    "    if get_top is not None:\n",
    "        return feature_importances['feature'][:get_top].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c9d8189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2 # подсчитываем память потребляемую изначальным датасетом\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns: # проходимся по всем колонкам\n",
    "        col_type = df[col].dtype  # узнаем тип колонки\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min() # смотрим минимальное значение признака\n",
    "            c_max = df[col].max() # смотрим максимальное значение признака\n",
    "            if str(col_type)[:3] == 'int':  # if int\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max: # сравниваем с int8\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max: # сравниваем с int16 и.т.д.\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else: # если был тип object, то меняем его тип на пандасовский тип 'category', на нем разные агрегации данных работают в разы быстрее\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2  # считаем сколько теперь у нас занято памяти\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))  # и выводим статистику\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85f01e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_learning_curve_plot(estimator, X, y, cv=3, n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, \n",
    "                                                            cv=cv, \n",
    "                                                            scoring='f1_macro',\n",
    "                                                            train_sizes=train_sizes, \n",
    "                                                            n_jobs=n_jobs)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.title(f\"Learning curves ({type(estimator).__name__})\")\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")     \n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d040ee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "kfold_cv = KFold(n_splits=3, shuffle=True, random_state=21)\n",
    "\n",
    "def run_cv(estimator, cv, X, y, scoring='f1_macro',  model_name=\"\"):\n",
    "    cv_res = cross_validate(estimator, X, y, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "    \n",
    "    print(\"%s: %s = %0.2f (+/- %0.2f)\" % (model_name,\n",
    "                                         scoring,\n",
    "                                         cv_res['test_score'].mean(),\n",
    "                                         cv_res['test_score'].std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1311380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choise_features(train, test, cat_feats):\n",
    "    \"\"\"Функция для проверки метрик и выбора признаков, cat_feats для категориальных признаков\"\"\"\n",
    "    X_train = train.drop(columns=['target'])\n",
    "    y_train = train['target']\n",
    "    X_test = test.drop(columns=['target'])\n",
    "    y_test = test['target']\n",
    "\n",
    "    display(y_train.value_counts(normalize=True), y_test.value_counts(normalize=True))\n",
    "    disbalance = y_train.value_counts()[0] / y_train.value_counts()[1]\n",
    "    frozen_params = {\n",
    "     'class_weights':[1, disbalance], \n",
    "     'silent':True,\n",
    "     'random_state':21,\n",
    "     'cat_features': cat_feats,\n",
    "     'eval_metric':'TotalF1',\n",
    "     'early_stopping_rounds':40\n",
    "    }    \n",
    "\n",
    "    model_catb = catb.CatBoostClassifier(**frozen_params, iterations=300, max_depth=5)\n",
    "    model_catb.fit(X_train, y_train, plot=True, eval_set=(X_test, y_test))\n",
    "    evaluate_preds(model_catb, X_train, X_test, y_train, y_test)\n",
    "    feature_importances = pd.DataFrame(zip(X_train.columns, model_catb.feature_importances_), \n",
    "                                       columns=['feature_name', 'importance'])\n",
    "    feature_importances.sort_values(by='importance', ascending=False)\n",
    "\n",
    "    return feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02f1a31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choise_features_model(train, test, model):\n",
    "    X_train = train.drop(columns=['target'])\n",
    "    y_train = train['target']\n",
    "    X_test = test.drop(columns=['target'])\n",
    "    y_test = test['target']\n",
    "\n",
    "    display(y_train.value_counts(normalize=True), y_test.value_counts(normalize=True))\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    evaluate_preds(model, X_train, X_test, y_train, y_test)\n",
    "    feature_importances = pd.DataFrame(zip(X_train.columns, model.feature_importances_), \n",
    "                                       columns=['feature_name', 'importance'])\n",
    "    feature_importances.sort_values(by='importance', ascending=False)\n",
    "\n",
    "    return feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fb3373c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = pathlib.Path().cwd()\n",
    "sys.path.append(cwd.as_posix())\n",
    "data_folder = cwd.joinpath('data')\n",
    "model_folder = cwd.joinpath('models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06ab54a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(data_folder.joinpath('train.csv'))\n",
    "test = pd.read_csv(data_folder.joinpath('test.csv'))\n",
    "\n",
    "train.drop(columns=['time_max'], inplace=True)\n",
    "test.drop(columns=['time_max'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2de80059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 54.57 MB\n",
      "Memory usage after optimization is: 15.83 MB\n",
      "Decreased by 71.0%\n",
      "Memory usage of dataframe is 23.39 MB\n",
      "Memory usage after optimization is: 6.78 MB\n",
      "Decreased by 71.0%\n"
     ]
    }
   ],
   "source": [
    "train = reduce_mem_usage(train)\n",
    "test = reduce_mem_usage(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e1383c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.90925\n",
       "1.0    0.09075\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "905da7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 286106 entries, 0 to 286105\n",
      "Data columns (total 25 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   target             286106 non-null  float32\n",
      " 1   id                 286106 non-null  int32  \n",
      " 2   buy_time_train     286106 non-null  int32  \n",
      " 3   vas_id             286106 non-null  int8   \n",
      " 4   time_delta         286106 non-null  float32\n",
      " 5   component_1        286106 non-null  float32\n",
      " 6   component_3        286106 non-null  float32\n",
      " 7   month              286106 non-null  int8   \n",
      " 8   day                286106 non-null  int16  \n",
      " 9   weekofyear         286106 non-null  int8   \n",
      " 10  how_old            286106 non-null  int32  \n",
      " 11  novelty            286106 non-null  float32\n",
      " 12  vas_id_1           286106 non-null  int8   \n",
      " 13  vas_id_2           286106 non-null  int8   \n",
      " 14  vas_id_4           286106 non-null  int8   \n",
      " 15  vas_id_5           286106 non-null  int8   \n",
      " 16  vas_id_6           286106 non-null  int8   \n",
      " 17  vas_id_7           286106 non-null  int8   \n",
      " 18  vas_id_8           286106 non-null  int8   \n",
      " 19  vas_id_9           286106 non-null  int8   \n",
      " 20  vas_id_ord         286106 non-null  int8   \n",
      " 21  vas_id_date_dif_1  286106 non-null  int16  \n",
      " 22  vas_id_date_dif_2  286106 non-null  int16  \n",
      " 23  vas_id_mean        286106 non-null  float32\n",
      " 24  log_vas_id_mean    286106 non-null  float32\n",
      "dtypes: float32(7), int16(3), int32(3), int8(12)\n",
      "memory usage: 15.8 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ce610e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>buy_time_train</th>\n",
       "      <th>vas_id</th>\n",
       "      <th>time_delta</th>\n",
       "      <th>component_1</th>\n",
       "      <th>component_3</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>...</th>\n",
       "      <th>vas_id_5</th>\n",
       "      <th>vas_id_6</th>\n",
       "      <th>vas_id_7</th>\n",
       "      <th>vas_id_8</th>\n",
       "      <th>vas_id_9</th>\n",
       "      <th>vas_id_ord</th>\n",
       "      <th>vas_id_date_dif_1</th>\n",
       "      <th>vas_id_date_dif_2</th>\n",
       "      <th>vas_id_mean</th>\n",
       "      <th>log_vas_id_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>286106.000000</td>\n",
       "      <td>2.861060e+05</td>\n",
       "      <td>2.861060e+05</td>\n",
       "      <td>286106.000000</td>\n",
       "      <td>286106.0</td>\n",
       "      <td>2.861060e+05</td>\n",
       "      <td>2.861060e+05</td>\n",
       "      <td>286106.000000</td>\n",
       "      <td>286106.000000</td>\n",
       "      <td>286106.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>286106.000000</td>\n",
       "      <td>286106.000000</td>\n",
       "      <td>286106.000000</td>\n",
       "      <td>286106.000000</td>\n",
       "      <td>286106.000000</td>\n",
       "      <td>286106.000000</td>\n",
       "      <td>286106.000000</td>\n",
       "      <td>286106.000000</td>\n",
       "      <td>286106.000000</td>\n",
       "      <td>286106.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.090750</td>\n",
       "      <td>2.092392e+06</td>\n",
       "      <td>1.541682e+09</td>\n",
       "      <td>2.953968</td>\n",
       "      <td>5456794.5</td>\n",
       "      <td>2.841800e+00</td>\n",
       "      <td>-3.327438e-03</td>\n",
       "      <td>10.682198</td>\n",
       "      <td>311.669430</td>\n",
       "      <td>44.524204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006309</td>\n",
       "      <td>0.015519</td>\n",
       "      <td>0.000930</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>0.001741</td>\n",
       "      <td>0.013243</td>\n",
       "      <td>0.149819</td>\n",
       "      <td>0.688511</td>\n",
       "      <td>0.090750</td>\n",
       "      <td>-3.269179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.287253</td>\n",
       "      <td>1.252824e+06</td>\n",
       "      <td>4.237310e+06</td>\n",
       "      <td>2.007375</td>\n",
       "      <td>4243547.5</td>\n",
       "      <td>4.133786e+08</td>\n",
       "      <td>3.919400e+06</td>\n",
       "      <td>1.569909</td>\n",
       "      <td>49.042937</td>\n",
       "      <td>7.006134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090777</td>\n",
       "      <td>0.135656</td>\n",
       "      <td>0.031381</td>\n",
       "      <td>0.030253</td>\n",
       "      <td>0.043005</td>\n",
       "      <td>0.147976</td>\n",
       "      <td>3.101163</td>\n",
       "      <td>6.663344</td>\n",
       "      <td>0.142978</td>\n",
       "      <td>1.142655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.531084e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.268137e+08</td>\n",
       "      <td>-1.142244e+08</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015690</td>\n",
       "      <td>-4.092966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.015328e+06</td>\n",
       "      <td>1.538341e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1814400.0</td>\n",
       "      <td>-1.267104e+08</td>\n",
       "      <td>-5.003790e+03</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>273.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020008</td>\n",
       "      <td>-3.862847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.041707e+06</td>\n",
       "      <td>1.543180e+09</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4838400.0</td>\n",
       "      <td>-1.267104e+08</td>\n",
       "      <td>-5.003789e+03</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>329.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023038</td>\n",
       "      <td>-3.728128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.061003e+06</td>\n",
       "      <td>1.544994e+09</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9072000.0</td>\n",
       "      <td>-1.267104e+08</td>\n",
       "      <td>-5.003789e+03</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023038</td>\n",
       "      <td>-3.728128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.362694e+06</td>\n",
       "      <td>1.546204e+09</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>15120000.0</td>\n",
       "      <td>1.419893e+09</td>\n",
       "      <td>1.522282e+09</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>364.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>0.437451</td>\n",
       "      <td>-0.824507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              target            id  buy_time_train         vas_id  time_delta  \\\n",
       "count  286106.000000  2.861060e+05    2.861060e+05  286106.000000    286106.0   \n",
       "mean        0.090750  2.092392e+06    1.541682e+09       2.953968   5456794.5   \n",
       "std         0.287253  1.252824e+06    4.237310e+06       2.007375   4243547.5   \n",
       "min         0.000000  2.000000e+00    1.531084e+09       1.000000         0.0   \n",
       "25%         0.000000  1.015328e+06    1.538341e+09       1.000000   1814400.0   \n",
       "50%         0.000000  2.041707e+06    1.543180e+09       2.000000   4838400.0   \n",
       "75%         0.000000  3.061003e+06    1.544994e+09       5.000000   9072000.0   \n",
       "max         1.000000  4.362694e+06    1.546204e+09       9.000000  15120000.0   \n",
       "\n",
       "        component_1   component_3          month            day  \\\n",
       "count  2.861060e+05  2.861060e+05  286106.000000  286106.000000   \n",
       "mean   2.841800e+00 -3.327438e-03      10.682198     311.669430   \n",
       "std    4.133786e+08  3.919400e+06       1.569909      49.042937   \n",
       "min   -1.268137e+08 -1.142244e+08       7.000000     189.000000   \n",
       "25%   -1.267104e+08 -5.003790e+03       9.000000     273.000000   \n",
       "50%   -1.267104e+08 -5.003789e+03      11.000000     329.000000   \n",
       "75%   -1.267104e+08 -5.003789e+03      12.000000     350.000000   \n",
       "max    1.419893e+09  1.522282e+09      12.000000     364.000000   \n",
       "\n",
       "          weekofyear  ...       vas_id_5       vas_id_6       vas_id_7  \\\n",
       "count  286106.000000  ...  286106.000000  286106.000000  286106.000000   \n",
       "mean       44.524204  ...       0.006309       0.015519       0.000930   \n",
       "std         7.006134  ...       0.090777       0.135656       0.031381   \n",
       "min        27.000000  ...       0.000000       0.000000       0.000000   \n",
       "25%        39.000000  ...       0.000000       0.000000       0.000000   \n",
       "50%        47.000000  ...       0.000000       0.000000       0.000000   \n",
       "75%        50.000000  ...       0.000000       0.000000       0.000000   \n",
       "max        52.000000  ...       2.000000       2.000000       2.000000   \n",
       "\n",
       "            vas_id_8       vas_id_9     vas_id_ord  vas_id_date_dif_1  \\\n",
       "count  286106.000000  286106.000000  286106.000000      286106.000000   \n",
       "mean        0.000692       0.001741       0.013243           0.149819   \n",
       "std         0.030253       0.043005       0.147976           3.101163   \n",
       "min         0.000000       0.000000       0.000000           0.000000   \n",
       "25%         0.000000       0.000000       0.000000           0.000000   \n",
       "50%         0.000000       0.000000       0.000000           0.000000   \n",
       "75%         0.000000       0.000000       0.000000           0.000000   \n",
       "max         2.000000       2.000000       2.000000         162.000000   \n",
       "\n",
       "       vas_id_date_dif_2    vas_id_mean  log_vas_id_mean  \n",
       "count      286106.000000  286106.000000    286106.000000  \n",
       "mean            0.688511       0.090750        -3.269179  \n",
       "std             6.663344       0.142978         1.142655  \n",
       "min             0.000000       0.015690        -4.092966  \n",
       "25%             0.000000       0.020008        -3.862847  \n",
       "50%             0.000000       0.023038        -3.728128  \n",
       "75%             0.000000       0.023038        -3.728128  \n",
       "max           168.000000       0.437451        -0.824507  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58972b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_NAME = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90814bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31310/1821944573.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(sample, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0    260142\n",
       "1.0    259640\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced=balance_df_by_target_advance(train, TARGET_NAME, method='over')\n",
    "df_balanced[TARGET_NAME].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38607e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    91213\n",
       "1    86510\n",
       "5    41032\n",
       "6    29457\n",
       "4    26265\n",
       "7     5800\n",
       "8     3811\n",
       "9     2018\n",
       "Name: vas_id, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['vas_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "563e7c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    145729\n",
       "2    107584\n",
       "1    104489\n",
       "4     97065\n",
       "5     47098\n",
       "7      6591\n",
       "9      6065\n",
       "8      5161\n",
       "Name: vas_id, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced['vas_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740380d5",
   "metadata": {},
   "source": [
    "В целом стратификация по vas_id не сильно нарушена."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a8fc321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    12886\n",
       "4     7882\n",
       "1     1993\n",
       "2     1825\n",
       "5      681\n",
       "9      452\n",
       "8      154\n",
       "7       91\n",
       "Name: vas_id, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['vas_id'].loc[train['target']==1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7437fe4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    129158\n",
       "4     78682\n",
       "1     19972\n",
       "2     18196\n",
       "5      6747\n",
       "9      4499\n",
       "8      1504\n",
       "7       882\n",
       "Name: vas_id, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced['vas_id'].loc[df_balanced['target']==1].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e903a3e",
   "metadata": {},
   "source": [
    "единиц стало больше на порядок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a28f668a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# для Катбуста\n",
    "def to_int(df, cat_feats):\n",
    "    df[cat_feats] = df[cat_feats].astype('int32')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1d4da6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = to_int(train, ['vas_id'])\n",
    "test = to_int(test, ['vas_id'])\n",
    "df_balanced = to_int(df_balanced, ['vas_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0eaf64c",
   "metadata": {},
   "source": [
    "# Выбор модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3442bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.019334463102759"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disbalance = train['target'].value_counts()[0] / train['target'].value_counts()[1]\n",
    "disbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd11feb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0019334463102758"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disbalance_bal = df_balanced['target'].value_counts()[0] / df_balanced['target'].value_counts()[1]\n",
    "disbalance_bal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc0d997",
   "metadata": {},
   "source": [
    "# XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def5bcbd",
   "metadata": {},
   "source": [
    "scale_pos_weight не помог"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c14b57d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually handling imbalance. Below is same as computing float(18501)/392318 \n",
    "#on the trainig dataset.\n",
    "# We are going to inversely assign the weights\n",
    "weight_ratio = float(len(train['target'][train['target'] == 0]))/float(len(train['target'][train['target'] == 1]))\n",
    "w_array = np.array([1]*train['target'].shape[0])\n",
    "w_array[train['target']==1] = weight_ratio\n",
    "w_array[train['target']==0] = 1- weight_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9d0527",
   "metadata": {},
   "source": [
    "sample_weight=w_array не повлиял на результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b1e80f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = xgb.XGBClassifier(random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3fee458a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.90925\n",
       "1.0    0.09075\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.909255\n",
       "1.0    0.090745\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.99      0.97    260142\n",
      "         1.0       0.80      0.38      0.52     25964\n",
      "\n",
      "    accuracy                           0.94    286106\n",
      "   macro avg       0.87      0.69      0.74    286106\n",
      "weighted avg       0.93      0.94      0.92    286106\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.99      0.96    111491\n",
      "         1.0       0.72      0.28      0.41     11127\n",
      "\n",
      "    accuracy                           0.93    122618\n",
      "   macro avg       0.83      0.64      0.68    122618\n",
      "weighted avg       0.91      0.93      0.91    122618\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0        0     1\n",
      "target              \n",
      "0.0     110291  1200\n",
      "1.0       7993  3134\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>0.003286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buy_time_train</td>\n",
       "      <td>0.066808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vas_id</td>\n",
       "      <td>0.011718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>time_delta</td>\n",
       "      <td>0.002412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>component_1</td>\n",
       "      <td>0.002726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>component_3</td>\n",
       "      <td>0.002734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>month</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>day</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>weekofyear</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>how_old</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>novelty</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>vas_id_1</td>\n",
       "      <td>0.108475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vas_id_2</td>\n",
       "      <td>0.033019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vas_id_4</td>\n",
       "      <td>0.033118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>vas_id_5</td>\n",
       "      <td>0.018012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>vas_id_6</td>\n",
       "      <td>0.033975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>vas_id_7</td>\n",
       "      <td>0.005855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>vas_id_8</td>\n",
       "      <td>0.001623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>vas_id_9</td>\n",
       "      <td>0.004039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>vas_id_ord</td>\n",
       "      <td>0.053078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>vas_id_date_dif_1</td>\n",
       "      <td>0.003898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>vas_id_date_dif_2</td>\n",
       "      <td>0.011130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>vas_id_mean</td>\n",
       "      <td>0.604096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>log_vas_id_mean</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature_name  importance\n",
       "0                  id    0.003286\n",
       "1      buy_time_train    0.066808\n",
       "2              vas_id    0.011718\n",
       "3          time_delta    0.002412\n",
       "4         component_1    0.002726\n",
       "5         component_3    0.002734\n",
       "6               month    0.000000\n",
       "7                 day    0.000000\n",
       "8          weekofyear    0.000000\n",
       "9             how_old    0.000000\n",
       "10            novelty    0.000000\n",
       "11           vas_id_1    0.108475\n",
       "12           vas_id_2    0.033019\n",
       "13           vas_id_4    0.033118\n",
       "14           vas_id_5    0.018012\n",
       "15           vas_id_6    0.033975\n",
       "16           vas_id_7    0.005855\n",
       "17           vas_id_8    0.001623\n",
       "18           vas_id_9    0.004039\n",
       "19         vas_id_ord    0.053078\n",
       "20  vas_id_date_dif_1    0.003898\n",
       "21  vas_id_date_dif_2    0.011130\n",
       "22        vas_id_mean    0.604096\n",
       "23    log_vas_id_mean    0.000000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choise_features_model(train, test, model_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8efe1e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_cv(model_xgb, kfold_cv, X_train, y_train, model_name=\"model_xgb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4f30e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = xgb.XGBClassifier(random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "27f45900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.500483\n",
       "1.0    0.499517\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.909255\n",
       "1.0    0.090745\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.86      0.91    260142\n",
      "         1.0       0.87      0.96      0.92    259640\n",
      "\n",
      "    accuracy                           0.91    519782\n",
      "   macro avg       0.92      0.91      0.91    519782\n",
      "weighted avg       0.92      0.91      0.91    519782\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.86      0.92    111491\n",
      "         1.0       0.40      0.94      0.56     11127\n",
      "\n",
      "    accuracy                           0.87    122618\n",
      "   macro avg       0.70      0.90      0.74    122618\n",
      "weighted avg       0.94      0.87      0.89    122618\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0       0      1\n",
      "target              \n",
      "0.0     95855  15636\n",
      "1.0       694  10433\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>0.004485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buy_time_train</td>\n",
       "      <td>0.089720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vas_id</td>\n",
       "      <td>0.013902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>time_delta</td>\n",
       "      <td>0.002626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>component_1</td>\n",
       "      <td>0.003071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>component_3</td>\n",
       "      <td>0.003913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>month</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>day</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>weekofyear</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>how_old</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>novelty</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>vas_id_1</td>\n",
       "      <td>0.218699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vas_id_2</td>\n",
       "      <td>0.019483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vas_id_4</td>\n",
       "      <td>0.019382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>vas_id_5</td>\n",
       "      <td>0.019698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>vas_id_6</td>\n",
       "      <td>0.010602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>vas_id_7</td>\n",
       "      <td>0.003455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>vas_id_8</td>\n",
       "      <td>0.001047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>vas_id_9</td>\n",
       "      <td>0.007911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>vas_id_ord</td>\n",
       "      <td>0.011983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>vas_id_date_dif_1</td>\n",
       "      <td>0.001660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>vas_id_date_dif_2</td>\n",
       "      <td>0.009381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>vas_id_mean</td>\n",
       "      <td>0.558984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>log_vas_id_mean</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature_name  importance\n",
       "0                  id    0.004485\n",
       "1      buy_time_train    0.089720\n",
       "2              vas_id    0.013902\n",
       "3          time_delta    0.002626\n",
       "4         component_1    0.003071\n",
       "5         component_3    0.003913\n",
       "6               month    0.000000\n",
       "7                 day    0.000000\n",
       "8          weekofyear    0.000000\n",
       "9             how_old    0.000000\n",
       "10            novelty    0.000000\n",
       "11           vas_id_1    0.218699\n",
       "12           vas_id_2    0.019483\n",
       "13           vas_id_4    0.019382\n",
       "14           vas_id_5    0.019698\n",
       "15           vas_id_6    0.010602\n",
       "16           vas_id_7    0.003455\n",
       "17           vas_id_8    0.001047\n",
       "18           vas_id_9    0.007911\n",
       "19         vas_id_ord    0.011983\n",
       "20  vas_id_date_dif_1    0.001660\n",
       "21  vas_id_date_dif_2    0.009381\n",
       "22        vas_id_mean    0.558984\n",
       "23    log_vas_id_mean    0.000000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choise_features_model(df_balanced, test, model_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "295575f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_cv(model_xgb, kfold_cv, X_train_balanced, y_train_balanced, model_name=\"model_xgb\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59d6c94",
   "metadata": {},
   "source": [
    "# LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "217f1e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.90925\n",
       "1.0    0.09075\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.909255\n",
       "1.0    0.090745\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.99      0.96    260142\n",
      "         1.0       0.79      0.33      0.47     25964\n",
      "\n",
      "    accuracy                           0.93    286106\n",
      "   macro avg       0.86      0.66      0.71    286106\n",
      "weighted avg       0.92      0.93      0.92    286106\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.99      0.96    111491\n",
      "         1.0       0.77      0.26      0.39     11127\n",
      "\n",
      "    accuracy                           0.93    122618\n",
      "   macro avg       0.85      0.63      0.67    122618\n",
      "weighted avg       0.92      0.93      0.91    122618\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0      0.0   1.0\n",
      "target              \n",
      "0.0     110624   867\n",
      "1.0       8230  2897\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buy_time_train</td>\n",
       "      <td>597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vas_id</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>time_delta</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>component_1</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>component_3</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>month</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>day</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>weekofyear</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>how_old</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>novelty</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>vas_id_1</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vas_id_2</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vas_id_4</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>vas_id_5</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>vas_id_6</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>vas_id_7</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>vas_id_8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>vas_id_9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>vas_id_ord</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>vas_id_date_dif_1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>vas_id_date_dif_2</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>vas_id_mean</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>log_vas_id_mean</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature_name  importance\n",
       "0                  id         582\n",
       "1      buy_time_train         597\n",
       "2              vas_id         153\n",
       "3          time_delta         239\n",
       "4         component_1         152\n",
       "5         component_3         282\n",
       "6               month           0\n",
       "7                 day           0\n",
       "8          weekofyear           0\n",
       "9             how_old          53\n",
       "10            novelty           0\n",
       "11           vas_id_1          86\n",
       "12           vas_id_2         113\n",
       "13           vas_id_4          57\n",
       "14           vas_id_5         116\n",
       "15           vas_id_6          58\n",
       "16           vas_id_7          35\n",
       "17           vas_id_8           3\n",
       "18           vas_id_9           7\n",
       "19         vas_id_ord          41\n",
       "20  vas_id_date_dif_1          17\n",
       "21  vas_id_date_dif_2         242\n",
       "22        vas_id_mean         159\n",
       "23    log_vas_id_mean           8"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lgbm = LGBMClassifier(random_state=21)\n",
    "choise_features_model(train, test, model_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bb2724da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.500483\n",
       "1.0    0.499517\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.909255\n",
       "1.0    0.090745\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.86      0.90    260142\n",
      "         1.0       0.87      0.96      0.91    259640\n",
      "\n",
      "    accuracy                           0.91    519782\n",
      "   macro avg       0.91      0.91      0.91    519782\n",
      "weighted avg       0.91      0.91      0.91    519782\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.86      0.92    111491\n",
      "         1.0       0.40      0.95      0.56     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.70      0.90      0.74    122618\n",
      "weighted avg       0.94      0.86      0.89    122618\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0     0.0    1.0\n",
      "target              \n",
      "0.0     95511  15980\n",
      "1.0       596  10531\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buy_time_train</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vas_id</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>time_delta</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>component_1</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>component_3</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>month</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>day</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>weekofyear</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>how_old</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>novelty</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>vas_id_1</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vas_id_2</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vas_id_4</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>vas_id_5</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>vas_id_6</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>vas_id_7</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>vas_id_8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>vas_id_9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>vas_id_ord</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>vas_id_date_dif_1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>vas_id_date_dif_2</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>vas_id_mean</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>log_vas_id_mean</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature_name  importance\n",
       "0                  id         565\n",
       "1      buy_time_train         652\n",
       "2              vas_id         203\n",
       "3          time_delta         272\n",
       "4         component_1         163\n",
       "5         component_3         293\n",
       "6               month           3\n",
       "7                 day           0\n",
       "8          weekofyear           0\n",
       "9             how_old          29\n",
       "10            novelty           0\n",
       "11           vas_id_1          80\n",
       "12           vas_id_2         114\n",
       "13           vas_id_4          51\n",
       "14           vas_id_5          90\n",
       "15           vas_id_6          63\n",
       "16           vas_id_7          24\n",
       "17           vas_id_8           2\n",
       "18           vas_id_9           9\n",
       "19         vas_id_ord          36\n",
       "20  vas_id_date_dif_1          13\n",
       "21  vas_id_date_dif_2         170\n",
       "22        vas_id_mean         162\n",
       "23    log_vas_id_mean           6"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lgbm = LGBMClassifier(random_state=21)\n",
    "choise_features_model(df_balanced, test, model_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a701fe0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_lgbm: f1_macro = 0.91 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "run_cv(model_lgbm, kfold_cv, df_balanced.drop(columns=['target']), df_balanced['target'], model_name=\"model_lgbm\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85074e3c",
   "metadata": {},
   "source": [
    "# CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e67c83b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_params = {\n",
    "     'class_weights':[1, disbalance], \n",
    "     'silent':True,\n",
    "     'random_state':21,\n",
    "     'cat_features': ['vas_id'],\n",
    "     'eval_metric':'F1',\n",
    "     'early_stopping_rounds':60\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9113ab1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.90925\n",
       "1.0    0.09075\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.909255\n",
       "1.0    0.090745\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.86      0.92    260142\n",
      "         1.0       0.41      0.96      0.58     25964\n",
      "\n",
      "    accuracy                           0.87    286106\n",
      "   macro avg       0.70      0.91      0.75    286106\n",
      "weighted avg       0.94      0.87      0.89    286106\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.87      0.93    111491\n",
      "         1.0       0.42      0.91      0.57     11127\n",
      "\n",
      "    accuracy                           0.88    122618\n",
      "   macro avg       0.70      0.89      0.75    122618\n",
      "weighted avg       0.94      0.88      0.90    122618\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0     0.0    1.0\n",
      "target              \n",
      "0.0     97296  14195\n",
      "1.0       985  10142\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>5.069729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buy_time_train</td>\n",
       "      <td>15.706955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vas_id</td>\n",
       "      <td>5.980055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>time_delta</td>\n",
       "      <td>4.426993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>component_1</td>\n",
       "      <td>1.510807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>component_3</td>\n",
       "      <td>3.495237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>month</td>\n",
       "      <td>0.334665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>day</td>\n",
       "      <td>12.292523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>weekofyear</td>\n",
       "      <td>7.234256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>how_old</td>\n",
       "      <td>3.356606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>novelty</td>\n",
       "      <td>7.792871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>vas_id_1</td>\n",
       "      <td>0.712852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vas_id_2</td>\n",
       "      <td>0.510266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vas_id_4</td>\n",
       "      <td>0.095826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>vas_id_5</td>\n",
       "      <td>0.342447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>vas_id_6</td>\n",
       "      <td>0.111511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>vas_id_7</td>\n",
       "      <td>0.031944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>vas_id_8</td>\n",
       "      <td>0.004416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>vas_id_9</td>\n",
       "      <td>0.024978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>vas_id_ord</td>\n",
       "      <td>0.072776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>vas_id_date_dif_1</td>\n",
       "      <td>0.053462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>vas_id_date_dif_2</td>\n",
       "      <td>0.412248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>vas_id_mean</td>\n",
       "      <td>10.804077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>log_vas_id_mean</td>\n",
       "      <td>19.622499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature_name  importance\n",
       "0                  id    5.069729\n",
       "1      buy_time_train   15.706955\n",
       "2              vas_id    5.980055\n",
       "3          time_delta    4.426993\n",
       "4         component_1    1.510807\n",
       "5         component_3    3.495237\n",
       "6               month    0.334665\n",
       "7                 day   12.292523\n",
       "8          weekofyear    7.234256\n",
       "9             how_old    3.356606\n",
       "10            novelty    7.792871\n",
       "11           vas_id_1    0.712852\n",
       "12           vas_id_2    0.510266\n",
       "13           vas_id_4    0.095826\n",
       "14           vas_id_5    0.342447\n",
       "15           vas_id_6    0.111511\n",
       "16           vas_id_7    0.031944\n",
       "17           vas_id_8    0.004416\n",
       "18           vas_id_9    0.024978\n",
       "19         vas_id_ord    0.072776\n",
       "20  vas_id_date_dif_1    0.053462\n",
       "21  vas_id_date_dif_2    0.412248\n",
       "22        vas_id_mean   10.804077\n",
       "23    log_vas_id_mean   19.622499"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_catb = catb.CatBoostClassifier(**frozen_params)\n",
    "choise_features_model(train, test, model_catb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "df793d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_catb: f1_macro = 0.89 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "run_cv(model_catb, kfold_cv, df_balanced.drop(columns=['target']), df_balanced['target'], model_name=\"model_catb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e29d7962",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = catb.CatBoostClassifier(**frozen_params,\n",
    "                                iterations=300,\n",
    "                                max_depth=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dbc741",
   "metadata": {},
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e1050f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df7e1ad6ca844f6c9da1bb78751e0512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bestTest = 0.9136468938\n",
      "bestIteration = 294\n",
      "\n",
      "0:\tloss: 0.9136469\tbest: 0.9136469 (0)\ttotal: 47.9s\tremaining: 7m 10s\n",
      "Stopped by overfitting detector  (60 iterations wait)\n",
      "\n",
      "bestTest = 0.9141980666\n",
      "bestIteration = 213\n",
      "\n",
      "1:\tloss: 0.9141981\tbest: 0.9141981 (1)\ttotal: 1m 28s\tremaining: 5m 55s\n",
      "\n",
      "bestTest = 0.9139767793\n",
      "bestIteration = 286\n",
      "\n",
      "2:\tloss: 0.9139768\tbest: 0.9141981 (1)\ttotal: 2m 15s\tremaining: 5m 15s\n",
      "Stopped by overfitting detector  (60 iterations wait)\n",
      "\n",
      "bestTest = 0.9142511396\n",
      "bestIteration = 113\n",
      "\n",
      "3:\tloss: 0.9142511\tbest: 0.9142511 (3)\ttotal: 2m 42s\tremaining: 4m 3s\n",
      "\n",
      "bestTest = 0.9136883124\n",
      "bestIteration = 293\n",
      "\n",
      "4:\tloss: 0.9136883\tbest: 0.9142511 (3)\ttotal: 3m 31s\tremaining: 3m 31s\n",
      "\n",
      "bestTest = 0.9146456536\n",
      "bestIteration = 244\n",
      "\n",
      "5:\tloss: 0.9146457\tbest: 0.9146457 (5)\ttotal: 4m 19s\tremaining: 2m 53s\n",
      "\n",
      "bestTest = 0.9137463048\n",
      "bestIteration = 284\n",
      "\n",
      "6:\tloss: 0.9137463\tbest: 0.9146457 (5)\ttotal: 5m 9s\tremaining: 2m 12s\n",
      "Stopped by overfitting detector  (60 iterations wait)\n",
      "\n",
      "bestTest = 0.9141425302\n",
      "bestIteration = 152\n",
      "\n",
      "7:\tloss: 0.9141425\tbest: 0.9146457 (5)\ttotal: 5m 44s\tremaining: 1m 26s\n",
      "\n",
      "bestTest = 0.9139436363\n",
      "bestIteration = 286\n",
      "\n",
      "8:\tloss: 0.9139436\tbest: 0.9146457 (5)\ttotal: 6m 34s\tremaining: 43.9s\n",
      "Stopped by overfitting detector  (60 iterations wait)\n",
      "\n",
      "bestTest = 0.9143406535\n",
      "bestIteration = 130\n",
      "\n",
      "9:\tloss: 0.9143407\tbest: 0.9146457 (5)\ttotal: 7m 6s\tremaining: 0us\n",
      "Estimating final quality...\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.9118554111\n",
      "bestIteration = 136\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.9114667579\n",
      "bestIteration = 218\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.9110793698\n",
      "bestIteration = 217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=3, random_state=21, shuffle=True)\n",
    "grid = {'learning_rate': [0.03, 0.1],\n",
    "        'l2_leaf_reg': [1, 3, 5, 7, 9]}\n",
    "grid_search = model.randomized_search(grid, train.drop(columns=['target']), train['target'], \n",
    "                                      n_iter=50, cv=cv, \n",
    "                                      stratified=True,\n",
    "                                      plot=True, refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dbdfe9c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iterations</th>\n",
       "      <th>test-F1-mean</th>\n",
       "      <th>test-F1-std</th>\n",
       "      <th>train-F1-mean</th>\n",
       "      <th>train-F1-std</th>\n",
       "      <th>test-Logloss-mean</th>\n",
       "      <th>test-Logloss-std</th>\n",
       "      <th>train-Logloss-mean</th>\n",
       "      <th>train-Logloss-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.903814</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.903814</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.577061</td>\n",
       "      <td>0.017978</td>\n",
       "      <td>0.577001</td>\n",
       "      <td>0.017621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.903806</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.903837</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.505464</td>\n",
       "      <td>0.012042</td>\n",
       "      <td>0.505315</td>\n",
       "      <td>0.011783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.903949</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.903941</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.453794</td>\n",
       "      <td>0.010168</td>\n",
       "      <td>0.453668</td>\n",
       "      <td>0.009798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.903809</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.903830</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.415301</td>\n",
       "      <td>0.009246</td>\n",
       "      <td>0.415156</td>\n",
       "      <td>0.008688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.904082</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>0.904223</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.384333</td>\n",
       "      <td>0.008510</td>\n",
       "      <td>0.384248</td>\n",
       "      <td>0.008003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>274</td>\n",
       "      <td>0.911272</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.912277</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.260355</td>\n",
       "      <td>0.000861</td>\n",
       "      <td>0.254692</td>\n",
       "      <td>0.001949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>275</td>\n",
       "      <td>0.911294</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.912279</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.260331</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.254655</td>\n",
       "      <td>0.001969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>276</td>\n",
       "      <td>0.911287</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.912267</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.260332</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>0.254634</td>\n",
       "      <td>0.001988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>277</td>\n",
       "      <td>0.911294</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.912279</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.260335</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>0.254613</td>\n",
       "      <td>0.002003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>278</td>\n",
       "      <td>0.911295</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.912278</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.260338</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>0.254598</td>\n",
       "      <td>0.002009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>279 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     iterations  test-F1-mean  test-F1-std  train-F1-mean  train-F1-std  \\\n",
       "0             0      0.903814     0.000434       0.903814      0.000217   \n",
       "1             1      0.903806     0.000422       0.903837      0.000183   \n",
       "2             2      0.903949     0.000200       0.903941      0.000405   \n",
       "3             3      0.903809     0.000426       0.903830      0.000192   \n",
       "4             4      0.904082     0.000634       0.904223      0.000344   \n",
       "..          ...           ...          ...            ...           ...   \n",
       "274         274      0.911272     0.000431       0.912277      0.000462   \n",
       "275         275      0.911294     0.000423       0.912279      0.000476   \n",
       "276         276      0.911287     0.000426       0.912267      0.000461   \n",
       "277         277      0.911294     0.000423       0.912279      0.000476   \n",
       "278         278      0.911295     0.000422       0.912278      0.000476   \n",
       "\n",
       "     test-Logloss-mean  test-Logloss-std  train-Logloss-mean  \\\n",
       "0             0.577061          0.017978            0.577001   \n",
       "1             0.505464          0.012042            0.505315   \n",
       "2             0.453794          0.010168            0.453668   \n",
       "3             0.415301          0.009246            0.415156   \n",
       "4             0.384333          0.008510            0.384248   \n",
       "..                 ...               ...                 ...   \n",
       "274           0.260355          0.000861            0.254692   \n",
       "275           0.260331          0.000872            0.254655   \n",
       "276           0.260332          0.000868            0.254634   \n",
       "277           0.260335          0.000863            0.254613   \n",
       "278           0.260338          0.000862            0.254598   \n",
       "\n",
       "     train-Logloss-std  \n",
       "0             0.017621  \n",
       "1             0.011783  \n",
       "2             0.009798  \n",
       "3             0.008688  \n",
       "4             0.008003  \n",
       "..                 ...  \n",
       "274           0.001949  \n",
       "275           0.001969  \n",
       "276           0.001988  \n",
       "277           0.002003  \n",
       "278           0.002009  \n",
       "\n",
       "[279 rows x 9 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(grid_search[\"cv_results\"])\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "70f696d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l2_leaf_reg': 5, 'learning_rate': 0.1}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search[\"params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d706ecc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.90925\n",
       "1.0    0.09075\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.909255\n",
       "1.0    0.090745\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.86      0.92    260142\n",
      "         1.0       0.40      0.96      0.56     25964\n",
      "\n",
      "    accuracy                           0.86    286106\n",
      "   macro avg       0.70      0.91      0.74    286106\n",
      "weighted avg       0.94      0.86      0.89    286106\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.86      0.92    111491\n",
      "         1.0       0.40      0.95      0.56     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.74    122618\n",
      "weighted avg       0.94      0.86      0.89    122618\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0     0.0    1.0\n",
      "target              \n",
      "0.0     95409  16082\n",
      "1.0       589  10538\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>1.151958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buy_time_train</td>\n",
       "      <td>8.009623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vas_id</td>\n",
       "      <td>7.125164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>time_delta</td>\n",
       "      <td>0.323743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>component_1</td>\n",
       "      <td>0.323002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>component_3</td>\n",
       "      <td>0.367257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>month</td>\n",
       "      <td>0.217135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>day</td>\n",
       "      <td>15.184036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>weekofyear</td>\n",
       "      <td>9.417172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>how_old</td>\n",
       "      <td>6.997710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>novelty</td>\n",
       "      <td>5.070496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>vas_id_1</td>\n",
       "      <td>0.916504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vas_id_2</td>\n",
       "      <td>0.612304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vas_id_4</td>\n",
       "      <td>0.060590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>vas_id_5</td>\n",
       "      <td>0.405821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>vas_id_6</td>\n",
       "      <td>0.087041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>vas_id_7</td>\n",
       "      <td>0.024175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>vas_id_8</td>\n",
       "      <td>0.001955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>vas_id_9</td>\n",
       "      <td>0.015950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>vas_id_ord</td>\n",
       "      <td>0.071433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>vas_id_date_dif_1</td>\n",
       "      <td>0.037680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>vas_id_date_dif_2</td>\n",
       "      <td>0.350473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>vas_id_mean</td>\n",
       "      <td>20.030965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>log_vas_id_mean</td>\n",
       "      <td>23.197815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature_name  importance\n",
       "0                  id    1.151958\n",
       "1      buy_time_train    8.009623\n",
       "2              vas_id    7.125164\n",
       "3          time_delta    0.323743\n",
       "4         component_1    0.323002\n",
       "5         component_3    0.367257\n",
       "6               month    0.217135\n",
       "7                 day   15.184036\n",
       "8          weekofyear    9.417172\n",
       "9             how_old    6.997710\n",
       "10            novelty    5.070496\n",
       "11           vas_id_1    0.916504\n",
       "12           vas_id_2    0.612304\n",
       "13           vas_id_4    0.060590\n",
       "14           vas_id_5    0.405821\n",
       "15           vas_id_6    0.087041\n",
       "16           vas_id_7    0.024175\n",
       "17           vas_id_8    0.001955\n",
       "18           vas_id_9    0.015950\n",
       "19         vas_id_ord    0.071433\n",
       "20  vas_id_date_dif_1    0.037680\n",
       "21  vas_id_date_dif_2    0.350473\n",
       "22        vas_id_mean   20.030965\n",
       "23    log_vas_id_mean   23.197815"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = catb.CatBoostClassifier(**frozen_params,\n",
    "                                iterations=300,\n",
    "                                max_depth=5,\n",
    "                                l2_leaf_reg=9, \n",
    "                                learning_rate=0.1\n",
    "                                )\n",
    "choise_features_model(train, test, best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9bc64311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold : 0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.92      0.95    111491\n",
      "         1.0       0.49      0.77      0.60     11127\n",
      "\n",
      "    accuracy                           0.91    122618\n",
      "   macro avg       0.73      0.85      0.77    122618\n",
      "weighted avg       0.93      0.91      0.92    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.8111111111111111\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.92      0.95    111491\n",
      "         1.0       0.50      0.76      0.60     11127\n",
      "\n",
      "    accuracy                           0.91    122618\n",
      "   macro avg       0.74      0.84      0.77    122618\n",
      "weighted avg       0.93      0.91      0.92    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.8222222222222223\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95    111491\n",
      "         1.0       0.50      0.74      0.60     11127\n",
      "\n",
      "    accuracy                           0.91    122618\n",
      "   macro avg       0.74      0.83      0.77    122618\n",
      "weighted avg       0.93      0.91      0.92    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95    111491\n",
      "         1.0       0.51      0.72      0.60     11127\n",
      "\n",
      "    accuracy                           0.91    122618\n",
      "   macro avg       0.74      0.82      0.77    122618\n",
      "weighted avg       0.93      0.91      0.92    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.8444444444444444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.94      0.95    111491\n",
      "         1.0       0.52      0.69      0.59     11127\n",
      "\n",
      "    accuracy                           0.91    122618\n",
      "   macro avg       0.74      0.81      0.77    122618\n",
      "weighted avg       0.93      0.91      0.92    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.8555555555555556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95    111491\n",
      "         1.0       0.54      0.64      0.58     11127\n",
      "\n",
      "    accuracy                           0.92    122618\n",
      "   macro avg       0.75      0.79      0.77    122618\n",
      "weighted avg       0.92      0.92      0.92    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.8666666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.95      0.96    111491\n",
      "         1.0       0.56      0.58      0.57     11127\n",
      "\n",
      "    accuracy                           0.92    122618\n",
      "   macro avg       0.76      0.77      0.76    122618\n",
      "weighted avg       0.92      0.92      0.92    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.8777777777777778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.97      0.96    111491\n",
      "         1.0       0.59      0.50      0.54     11127\n",
      "\n",
      "    accuracy                           0.92    122618\n",
      "   macro avg       0.77      0.73      0.75    122618\n",
      "weighted avg       0.92      0.92      0.92    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.888888888888889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96    111491\n",
      "         1.0       0.63      0.41      0.49     11127\n",
      "\n",
      "    accuracy                           0.92    122618\n",
      "   macro avg       0.79      0.69      0.73    122618\n",
      "weighted avg       0.91      0.92      0.92    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.99      0.96    111491\n",
      "         1.0       0.69      0.32      0.44     11127\n",
      "\n",
      "    accuracy                           0.93    122618\n",
      "   macro avg       0.81      0.65      0.70    122618\n",
      "weighted avg       0.91      0.93      0.91    122618\n",
      "\n",
      "***************************\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict_proba(test.drop(columns=['target']))\n",
    "\n",
    "for i in np.linspace(0.8, 0.9, num=10):\n",
    "    print(f\"threshold : {i}\")\n",
    "    print(classification_report(test['target'], (y_pred[:, 1] > i) * 1))\n",
    "    print('***************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1318339",
   "metadata": {},
   "source": [
    "# Теперь попробую LGBMClassifier на сбалансированных данных.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "607a0de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lgbm = LGBMClassifier(random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8a7557",
   "metadata": {},
   "source": [
    "# Выбор метода балансировки датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21536623",
   "metadata": {},
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9cb880",
   "metadata": {},
   "source": [
    "conda update conda -y && conda update python -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3439b624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.904999\n",
       "1.0    0.095001\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.909255\n",
       "1.0    0.090745\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.99      0.96    247337\n",
      "         1.0       0.78      0.39      0.52     25964\n",
      "\n",
      "    accuracy                           0.93    273301\n",
      "   macro avg       0.86      0.69      0.74    273301\n",
      "weighted avg       0.92      0.93      0.92    273301\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96    111491\n",
      "         1.0       0.68      0.34      0.46     11127\n",
      "\n",
      "    accuracy                           0.93    122618\n",
      "   macro avg       0.81      0.66      0.71    122618\n",
      "weighted avg       0.91      0.93      0.91    122618\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0      0.0   1.0\n",
      "target              \n",
      "0.0     109694  1797\n",
      "1.0       7303  3824\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buy_time_train</td>\n",
       "      <td>613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vas_id</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>time_delta</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>component_1</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>component_3</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>month</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>day</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>weekofyear</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>how_old</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>novelty</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>vas_id_1</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vas_id_2</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vas_id_4</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>vas_id_5</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>vas_id_6</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>vas_id_7</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>vas_id_8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>vas_id_9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>vas_id_ord</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>vas_id_date_dif_1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>vas_id_date_dif_2</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>vas_id_mean</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>log_vas_id_mean</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature_name  importance\n",
       "0                  id         599\n",
       "1      buy_time_train         613\n",
       "2              vas_id         155\n",
       "3          time_delta         248\n",
       "4         component_1         144\n",
       "5         component_3         262\n",
       "6               month           1\n",
       "7                 day           0\n",
       "8          weekofyear           0\n",
       "9             how_old          56\n",
       "10            novelty           0\n",
       "11           vas_id_1          84\n",
       "12           vas_id_2         110\n",
       "13           vas_id_4          69\n",
       "14           vas_id_5         115\n",
       "15           vas_id_6          58\n",
       "16           vas_id_7          33\n",
       "17           vas_id_8           3\n",
       "18           vas_id_9           9\n",
       "19         vas_id_ord          44\n",
       "20  vas_id_date_dif_1          15\n",
       "21  vas_id_date_dif_2         234\n",
       "22        vas_id_mean         140\n",
       "23    log_vas_id_mean           8"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced_tomek = balance_df_by_target_advance(train, 'target', method='tomek')\n",
    "\n",
    "X_train_tomek = df_balanced_tomek.drop(columns=TARGET_NAME)\n",
    "y_train_tomek = df_balanced_tomek[TARGET_NAME]\n",
    "\n",
    "model_lgbm_t = LGBMClassifier(random_state=21)\n",
    "choise_features_model(df_balanced_tomek, test, model_lgbm_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4125809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.5\n",
       "1.0    0.5\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.909255\n",
       "1.0    0.090745\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.89      0.93    260142\n",
      "         1.0       0.90      0.97      0.94    260142\n",
      "\n",
      "    accuracy                           0.93    520284\n",
      "   macro avg       0.94      0.93      0.93    520284\n",
      "weighted avg       0.94      0.93      0.93    520284\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.87      0.92    111491\n",
      "         1.0       0.41      0.91      0.56     11127\n",
      "\n",
      "    accuracy                           0.87    122618\n",
      "   macro avg       0.70      0.89      0.74    122618\n",
      "weighted avg       0.94      0.87      0.89    122618\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0     0.0    1.0\n",
      "target              \n",
      "0.0     96676  14815\n",
      "1.0      1001  10126\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(520284, 25)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_smote = balance_df_by_target_advance(train, 'target', method='smote')\n",
    "\n",
    "model_lgbm_s = LGBMClassifier(random_state=21)\n",
    "choise_features_model(df_smote, test, model_lgbm_s)\n",
    "df_smote.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f15f476",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31310/1821944573.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(tmp.iloc[\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.5\n",
       "1.0    0.5\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.909255\n",
       "1.0    0.090745\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.85      0.90     25964\n",
      "         1.0       0.87      0.96      0.91     25964\n",
      "\n",
      "    accuracy                           0.91     51928\n",
      "   macro avg       0.91      0.91      0.91     51928\n",
      "weighted avg       0.91      0.91      0.91     51928\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.85      0.92    111491\n",
      "         1.0       0.39      0.95      0.56     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.74    122618\n",
      "weighted avg       0.94      0.86      0.89    122618\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0     0.0    1.0\n",
      "target              \n",
      "0.0     95228  16263\n",
      "1.0       582  10545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(51928, 25)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_under = balance_df_by_target_advance(train, 'target', method='under')\n",
    "\n",
    "model_lgbm_u = LGBMClassifier(random_state=21)\n",
    "choise_features_model(df_under, test, model_lgbm_u)\n",
    "df_under.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3de9a0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_lgbm_u: f1_macro = 0.90 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "run_cv(model_lgbm_u, kfold_cv, df_under.drop(columns=['target']), df_under['target'],\n",
    "       model_name=\"model_lgbm_u\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0653923",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_under"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f4909a",
   "metadata": {},
   "source": [
    "# Удаление признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5db0dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True, False, False, False,\n",
       "        True, False,  True,  True,  True,  True,  True, False, False,\n",
       "       False,  True, False,  True,  True, False])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = LGBMClassifier(random_state=21)\n",
    "\n",
    "min_features_to_select = 10\n",
    "selector = RFECV(estimator, step=1, cv=5,  scoring='f1_macro', \n",
    "                 min_features_to_select=min_features_to_select)\n",
    "selector = selector.fit(train.drop(columns=['target']), train['target'])\n",
    "selector.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e201496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features : 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jb/anaconda3/envs/MEGA_project/lib/python3.9/site-packages/sklearn/utils/deprecation.py:103: FutureWarning: The `grid_scores_` attribute is deprecated in version 1.0 in favor of `cv_results_` and will be removed in version 1.2.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Optimal number of features : %d\" % selector.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (accuracy)\")\n",
    "plt.plot(\n",
    "    range(min_features_to_select, len(selector.grid_scores_) + min_features_to_select),\n",
    "    selector.grid_scores_,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c401a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True, False, False, False,\n",
       "        True, False,  True,  True,  True,  True,  True, False, False,\n",
       "       False,  True, False,  True,  True, False])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29dc6a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'buy_time_train',\n",
       " 'vas_id',\n",
       " 'time_delta',\n",
       " 'component_1',\n",
       " 'component_3',\n",
       " 'how_old',\n",
       " 'vas_id_1',\n",
       " 'vas_id_2',\n",
       " 'vas_id_4',\n",
       " 'vas_id_5',\n",
       " 'vas_id_6',\n",
       " 'vas_id_ord',\n",
       " 'vas_id_date_dif_2',\n",
       " 'vas_id_mean',\n",
       " 'target']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = np.array(train.drop(columns=['target']).columns.to_list())\n",
    "mask = np.array(selector.support_)\n",
    "last_col = list(value[mask])\n",
    "last_col.extend(['target'])\n",
    "last_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "71494bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_col = ['id',\n",
    " 'buy_time_train',\n",
    " 'vas_id',\n",
    " 'time_delta',\n",
    " 'component_1',\n",
    " 'component_3',\n",
    " 'how_old',\n",
    " 'vas_id_1',\n",
    " 'vas_id_2',\n",
    " 'vas_id_4',\n",
    " 'vas_id_5',\n",
    " 'vas_id_6',\n",
    " 'vas_id_7',\n",
    " 'vas_id_8',\n",
    " 'vas_id_ord',\n",
    " 'vas_id_date_dif_1',\n",
    " 'vas_id_date_dif_2',\n",
    " 'vas_id_mean',\n",
    " 'log_vas_id_mean',\n",
    " 'target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5a9c4e",
   "metadata": {},
   "source": [
    "# Укорачиваю признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a1bdd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_short = train[last_col]\n",
    "test_short = test[last_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9eee76a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.5\n",
       "1.0    0.5\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.909255\n",
       "1.0    0.090745\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.85      0.90     25964\n",
      "         1.0       0.87      0.96      0.91     25964\n",
      "\n",
      "    accuracy                           0.91     51928\n",
      "   macro avg       0.91      0.91      0.91     51928\n",
      "weighted avg       0.91      0.91      0.91     51928\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.86      0.92    111491\n",
      "         1.0       0.39      0.95      0.56     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.74    122618\n",
      "weighted avg       0.94      0.86      0.89    122618\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0     0.0    1.0\n",
      "target              \n",
      "0.0     95340  16151\n",
      "1.0       587  10540\n"
     ]
    }
   ],
   "source": [
    "estimator = LGBMClassifier(random_state=21)\n",
    "feature_importances = choise_features_model(train_short, test_short, estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c72411",
   "metadata": {},
   "source": [
    "Скор лучше не стал, но для ускорения приму этот результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f6b7480e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_short, test_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e01893e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buy_time_train</td>\n",
       "      <td>526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vas_id</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>time_delta</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>component_1</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>component_3</td>\n",
       "      <td>356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>how_old</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vas_id_1</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vas_id_2</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vas_id_4</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>vas_id_5</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>vas_id_6</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>vas_id_7</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vas_id_8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>vas_id_ord</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>vas_id_date_dif_1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>vas_id_date_dif_2</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>vas_id_mean</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>log_vas_id_mean</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature_name  importance\n",
       "0                  id         599\n",
       "1      buy_time_train         526\n",
       "2              vas_id         179\n",
       "3          time_delta         308\n",
       "4         component_1         228\n",
       "5         component_3         356\n",
       "6             how_old          62\n",
       "7            vas_id_1          71\n",
       "8            vas_id_2         106\n",
       "9            vas_id_4          44\n",
       "10           vas_id_5          89\n",
       "11           vas_id_6          55\n",
       "12           vas_id_7          18\n",
       "13           vas_id_8           2\n",
       "14         vas_id_ord          25\n",
       "15  vas_id_date_dif_1          15\n",
       "16  vas_id_date_dif_2         169\n",
       "17        vas_id_mean         136\n",
       "18    log_vas_id_mean          12"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d84b68",
   "metadata": {},
   "source": [
    "То что id самый важный - косяк. Но думаю при оптимизации модели это исправится."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a0489816",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_file = data_folder.joinpath(\"train_boost.csv\")\n",
    "test_data_file = data_folder.joinpath(\"test_boost.csv\")\n",
    "\n",
    "train.to_csv(train_data_file, index=False, header=False)\n",
    "test.to_csv(test_data_file, index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f82fa1c",
   "metadata": {},
   "source": [
    "# Подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e167359",
   "metadata": {},
   "source": [
    "!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "60025a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, tpe\n",
    "from hyperopt.fmin import fmin\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer\n",
    "import lightgbm as lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bd52433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(['target'], axis=1)\n",
    "Y = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1f2d6e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(truth, predictions):\n",
    "    g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
    "    g = g[np.lexsort((g[:,2], -1*g[:,1]))]\n",
    "    gs = g[:,0].cumsum().sum() / g[:,0].sum()\n",
    "    gs -= (len(truth) + 1) / 2.\n",
    "    return gs / len(truth)\n",
    "\n",
    "def gini_lgb(truth, predictions):\n",
    "    score = gini(truth, predictions) / gini(truth, truth)\n",
    "    return 'gini', score, True\n",
    "\n",
    "def gini_sklearn(truth, predictions):\n",
    "    return gini(truth, predictions) / gini(truth, truth)\n",
    "\n",
    "gini_scorer = make_scorer(gini_sklearn, greater_is_better=True, needs_proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8c42429f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n",
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n",
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n",
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini 0.895 params {'num_leaves': 44, 'colsample_bytree': '0.659'}\n",
      " 10%|█         | 1/10 [00:16<02:26, 16.32s/trial, best loss: 0.8954536478297455]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n",
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n",
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n",
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n",
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini 0.895 params {'num_leaves': 88, 'colsample_bytree': '0.526'}               \n",
      " 20%|██        | 2/10 [00:37<02:34, 19.25s/trial, best loss: 0.8952100140950972]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n",
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n",
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n",
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n",
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini 0.895 params {'num_leaves': 82, 'colsample_bytree': '0.776'}               \n",
      " 30%|███       | 3/10 [01:00<02:26, 20.98s/trial, best loss: 0.8947775594528572]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n",
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n",
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n",
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n",
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini 0.895 params {'num_leaves': 50, 'colsample_bytree': '0.554'}               \n",
      " 40%|████      | 4/10 [01:17<01:55, 19.25s/trial, best loss: 0.8947775594528572]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n",
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n",
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n",
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n",
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini 0.896 params {'num_leaves': 40, 'colsample_bytree': '0.578'}               \n",
      " 50%|█████     | 5/10 [01:29<01:24, 16.82s/trial, best loss: 0.8947775594528572]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n",
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n",
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n",
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n",
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini 0.895 params {'num_leaves': 36, 'colsample_bytree': '0.639'}               \n",
      " 60%|██████    | 6/10 [01:41<01:00, 15.21s/trial, best loss: 0.8947775594528572]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n",
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n",
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n",
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n",
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini 0.895 params {'num_leaves': 84, 'colsample_bytree': '0.496'}               \n",
      " 70%|███████   | 7/10 [02:04<00:52, 17.58s/trial, best loss: 0.8947775594528572]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n",
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n",
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n",
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n",
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini 0.894 params {'num_leaves': 118, 'colsample_bytree': '0.311'}              \n",
      " 80%|████████  | 8/10 [02:32<00:42, 21.05s/trial, best loss: 0.8936256519767964]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n",
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n",
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n",
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n",
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini 0.895 params {'num_leaves': 62, 'colsample_bytree': '0.428'}               \n",
      " 90%|█████████ | 9/10 [02:48<00:19, 19.28s/trial, best loss: 0.8936256519767964]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n",
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n",
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n",
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n",
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini 0.894 params {'num_leaves': 10, 'colsample_bytree': '0.891'}               \n",
      "100%|██████████| 10/10 [02:56<00:00, 17.64s/trial, best loss: 0.8935034988687068]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31310/3082248066.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  g = np.asarray(np.c_[truth, predictions, np.arange(len(truth)) ], dtype=np.float)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def objective(params):\n",
    "    params = {\n",
    "        'num_leaves': int(params['num_leaves']),\n",
    "        'colsample_bytree': '{:.3f}'.format(params['colsample_bytree']),\n",
    "    }\n",
    "    \n",
    "    clf = lgbm.LGBMClassifier(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.01,\n",
    "        **params\n",
    "    )\n",
    "    \n",
    "    score = cross_val_score(clf, X, Y, scoring=gini_scorer, cv=StratifiedKFold()).mean()\n",
    "    print(\"Gini {:.3f} params {}\".format(score, params))\n",
    "    return score\n",
    "\n",
    "space = {\n",
    "    'num_leaves': hp.quniform('num_leaves', 8, 128, 2),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.3, 1.0),\n",
    "}\n",
    "\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b1eb3c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperopt estimated optimum {'colsample_bytree': 0.8913036223449964, 'num_leaves': 10.0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Hyperopt estimated optimum {}\".format(best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "962f9cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model = lgbm.LGBMClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.01,\n",
    "    num_leaves=10,\n",
    "    colsample_bytree=0.8913036223449964\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "865498e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.5\n",
       "1.0    0.5\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0    0.909255\n",
       "1.0    0.090745\n",
       "Name: target, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.85      0.90     25964\n",
      "         1.0       0.86      0.96      0.91     25964\n",
      "\n",
      "    accuracy                           0.90     51928\n",
      "   macro avg       0.91      0.90      0.90     51928\n",
      "weighted avg       0.91      0.90      0.90     51928\n",
      "\n",
      "TEST\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.85      0.92    111491\n",
      "         1.0       0.39      0.95      0.55     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.74    122618\n",
      "weighted avg       0.94      0.86      0.88    122618\n",
      "\n",
      "CONFUSION MATRIX\n",
      "\n",
      "col_0     0.0    1.0\n",
      "target              \n",
      "0.0     95052  16439\n",
      "1.0       567  10560\n"
     ]
    }
   ],
   "source": [
    "feature_importances = choise_features_model(train, test, lgbm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c8ff09c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold : 0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.79      0.88    111491\n",
      "         1.0       0.31      0.96      0.47     11127\n",
      "\n",
      "    accuracy                           0.80    122618\n",
      "   macro avg       0.65      0.87      0.67    122618\n",
      "weighted avg       0.93      0.80      0.84    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.13333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.83      0.90    111491\n",
      "         1.0       0.36      0.96      0.52     11127\n",
      "\n",
      "    accuracy                           0.84    122618\n",
      "   macro avg       0.68      0.89      0.71    122618\n",
      "weighted avg       0.94      0.84      0.87    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.16666666666666669\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.85      0.91    111491\n",
      "         1.0       0.38      0.95      0.54     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.73    122618\n",
      "weighted avg       0.94      0.86      0.88    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.85      0.91    111491\n",
      "         1.0       0.38      0.95      0.54     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.73    122618\n",
      "weighted avg       0.94      0.86      0.88    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.23333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.85      0.91    111491\n",
      "         1.0       0.38      0.95      0.55     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.73    122618\n",
      "weighted avg       0.94      0.86      0.88    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.26666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.85      0.91    111491\n",
      "         1.0       0.38      0.95      0.55     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.73    122618\n",
      "weighted avg       0.94      0.86      0.88    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.30000000000000004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.85      0.92    111491\n",
      "         1.0       0.38      0.95      0.55     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.73    122618\n",
      "weighted avg       0.94      0.86      0.88    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.33333333333333337\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.85      0.92    111491\n",
      "         1.0       0.39      0.95      0.55     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.73    122618\n",
      "weighted avg       0.94      0.86      0.88    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.3666666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.85      0.92    111491\n",
      "         1.0       0.39      0.95      0.55     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.73    122618\n",
      "weighted avg       0.94      0.86      0.88    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.85      0.92    111491\n",
      "         1.0       0.39      0.95      0.55     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.73    122618\n",
      "weighted avg       0.94      0.86      0.88    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.43333333333333335\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.85      0.92    111491\n",
      "         1.0       0.39      0.95      0.55     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.74    122618\n",
      "weighted avg       0.94      0.86      0.88    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.4666666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.85      0.92    111491\n",
      "         1.0       0.39      0.95      0.55     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.74    122618\n",
      "weighted avg       0.94      0.86      0.88    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.85      0.92    111491\n",
      "         1.0       0.39      0.95      0.55     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.74    122618\n",
      "weighted avg       0.94      0.86      0.88    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.5333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.85      0.92    111491\n",
      "         1.0       0.39      0.95      0.55     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.74    122618\n",
      "weighted avg       0.94      0.86      0.89    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.5666666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.85      0.92    111491\n",
      "         1.0       0.39      0.95      0.55     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.74    122618\n",
      "weighted avg       0.94      0.86      0.89    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.85      0.92    111491\n",
      "         1.0       0.39      0.95      0.55     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.74    122618\n",
      "weighted avg       0.94      0.86      0.89    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.6333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.85      0.92    111491\n",
      "         1.0       0.39      0.95      0.55     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.74    122618\n",
      "weighted avg       0.94      0.86      0.89    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.87      0.93    111491\n",
      "         1.0       0.41      0.92      0.57     11127\n",
      "\n",
      "    accuracy                           0.87    122618\n",
      "   macro avg       0.70      0.90      0.75    122618\n",
      "weighted avg       0.94      0.87      0.89    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.88      0.93    111491\n",
      "         1.0       0.43      0.90      0.58     11127\n",
      "\n",
      "    accuracy                           0.88    122618\n",
      "   macro avg       0.71      0.89      0.76    122618\n",
      "weighted avg       0.94      0.88      0.90    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.7333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.89      0.94    111491\n",
      "         1.0       0.45      0.87      0.59     11127\n",
      "\n",
      "    accuracy                           0.89    122618\n",
      "   macro avg       0.72      0.88      0.76    122618\n",
      "weighted avg       0.94      0.89      0.91    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.7666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.90      0.94    111491\n",
      "         1.0       0.46      0.85      0.59     11127\n",
      "\n",
      "    accuracy                           0.89    122618\n",
      "   macro avg       0.72      0.88      0.77    122618\n",
      "weighted avg       0.94      0.89      0.91    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.7999999999999999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.92      0.95    111491\n",
      "         1.0       0.49      0.75      0.60     11127\n",
      "\n",
      "    accuracy                           0.91    122618\n",
      "   macro avg       0.73      0.84      0.77    122618\n",
      "weighted avg       0.93      0.91      0.92    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.8333333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95    111491\n",
      "         1.0       0.51      0.72      0.60     11127\n",
      "\n",
      "    accuracy                           0.91    122618\n",
      "   macro avg       0.74      0.83      0.77    122618\n",
      "weighted avg       0.93      0.91      0.92    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.8666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.96    111491\n",
      "         1.0       0.57      0.53      0.55     11127\n",
      "\n",
      "    accuracy                           0.92    122618\n",
      "   macro avg       0.76      0.75      0.76    122618\n",
      "weighted avg       0.92      0.92      0.92    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.99      0.96    111491\n",
      "         1.0       0.77      0.24      0.37     11127\n",
      "\n",
      "    accuracy                           0.92    122618\n",
      "   macro avg       0.85      0.62      0.66    122618\n",
      "weighted avg       0.91      0.92      0.91    122618\n",
      "\n",
      "***************************\n"
     ]
    }
   ],
   "source": [
    "y_pred = lgbm_model.predict_proba(test.drop(columns=['target']))\n",
    "\n",
    "for i in np.linspace(0.1, 0.9, num=25):\n",
    "    print(f\"threshold : {i}\")\n",
    "    print(classification_report(test['target'], (y_pred[:, 1] > i) * 1))\n",
    "    print('***************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23106a1e",
   "metadata": {},
   "source": [
    "переобучение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc428c92",
   "metadata": {},
   "source": [
    "# ЛУЧШАЯ НЕЙРОННАЯ СЕТЬ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1431f54",
   "metadata": {},
   "source": [
    "на сбалансированном трейне"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bb8d3c",
   "metadata": {},
   "source": [
    "!pip install -U tensorflow-addons==0.18.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcca878",
   "metadata": {},
   "source": [
    "!pip install tensorflow==2.9.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "09d940eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-27 16:39:34.786150: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-27 16:39:34.786180: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import callbacks\n",
    "from keras import models\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a601559c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.18.0'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfa.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "57b53836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: (286106, 25)\n",
      "Test dataset shape: (122618, 25)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(data_folder.joinpath('train.csv'))\n",
    "test_data = pd.read_csv(data_folder.joinpath('test.csv'))\n",
    "\n",
    "train_data.drop(columns=['time_max'], inplace=True)\n",
    "test_data.drop(columns=['time_max'], inplace=True)\n",
    "\n",
    "print(f\"Train dataset shape: {train_data.shape}\")\n",
    "print(f\"Test dataset shape: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b598969d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_31310/1821944573.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(sample, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "train_data = balance_df_by_target_advance(train_data, 'target', method='over')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0649f5cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['target', 'id', 'buy_time_train', 'vas_id', 'time_delta', 'component_1',\n",
       "       'component_3', 'month', 'day', 'weekofyear', 'how_old', 'novelty',\n",
       "       'vas_id_1', 'vas_id_2', 'vas_id_4', 'vas_id_5', 'vas_id_6', 'vas_id_7',\n",
       "       'vas_id_8', 'vas_id_9', 'vas_id_ord', 'vas_id_date_dif_1',\n",
       "       'vas_id_date_dif_2', 'vas_id_mean', 'log_vas_id_mean'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b80c8869",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_columns = ['target', 'id', 'buy_time_train', 'vas_id', 'time_delta', 'component_1',\n",
    "       'component_3', 'month', 'day', 'weekofyear', 'how_old', 'novelty',\n",
    "       'vas_id_1', 'vas_id_2', 'vas_id_4', 'vas_id_5', 'vas_id_6', 'vas_id_7',\n",
    "       'vas_id_8', 'vas_id_9', 'vas_id_ord', 'vas_id_date_dif_1',\n",
    "       'vas_id_date_dif_2', 'vas_id_mean', 'log_vas_id_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "10fad2cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>buy_time_train</th>\n",
       "      <th>vas_id</th>\n",
       "      <th>time_delta</th>\n",
       "      <th>component_1</th>\n",
       "      <th>component_3</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>...</th>\n",
       "      <th>vas_id_5</th>\n",
       "      <th>vas_id_6</th>\n",
       "      <th>vas_id_7</th>\n",
       "      <th>vas_id_8</th>\n",
       "      <th>vas_id_9</th>\n",
       "      <th>vas_id_ord</th>\n",
       "      <th>vas_id_date_dif_1</th>\n",
       "      <th>vas_id_date_dif_2</th>\n",
       "      <th>vas_id_mean</th>\n",
       "      <th>log_vas_id_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.864351</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.069795</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017423</td>\n",
       "      <td>0.111624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990180</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.946115</td>\n",
       "      <td>0.069798</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.217731</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.069795</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.674328</td>\n",
       "      <td>0.885016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052879</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.069795</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.395337</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.069795</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.674328</td>\n",
       "      <td>0.885016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   target        id  buy_time_train  vas_id  time_delta  component_1  \\\n",
       "0     0.0  0.864351            0.96   0.000        0.00     0.000067   \n",
       "1     1.0  0.990180            0.92   0.625        0.76     0.946115   \n",
       "2     1.0  0.217731            0.68   0.375        0.12     0.000067   \n",
       "3     1.0  0.052879            0.92   0.625        0.00     0.000067   \n",
       "4     1.0  0.395337            0.96   0.375        0.84     0.000067   \n",
       "\n",
       "   component_3  month   day  weekofyear  ...  vas_id_5  vas_id_6  vas_id_7  \\\n",
       "0     0.069795    1.0  0.96        0.96  ...       0.0       0.0       0.0   \n",
       "1     0.069798    1.0  0.92        0.92  ...       0.0       0.5       0.0   \n",
       "2     0.069795    0.8  0.68        0.68  ...       0.0       0.0       0.0   \n",
       "3     0.069795    1.0  0.92        0.92  ...       0.0       0.0       0.0   \n",
       "4     0.069795    1.0  0.96        0.96  ...       0.0       0.5       0.0   \n",
       "\n",
       "   vas_id_8  vas_id_9  vas_id_ord  vas_id_date_dif_1  vas_id_date_dif_2  \\\n",
       "0       0.0       0.0         0.0                0.0                0.0   \n",
       "1       0.0       0.0         0.0                0.0                0.0   \n",
       "2       0.0       0.0         0.5                0.0                0.0   \n",
       "3       0.0       0.0         0.0                0.0                0.0   \n",
       "4       0.0       0.0         0.0                0.0                0.0   \n",
       "\n",
       "   vas_id_mean  log_vas_id_mean  \n",
       "0     0.017423         0.111624  \n",
       "1     1.000000         1.000000  \n",
       "2     0.674328         0.885016  \n",
       "3     1.000000         1.000000  \n",
       "4     0.674328         0.885016  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_data)\n",
    "train_data = pd.DataFrame(scaler.transform(train_data), columns=train_data_columns)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "73a33f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>buy_time_train</th>\n",
       "      <th>vas_id</th>\n",
       "      <th>time_delta</th>\n",
       "      <th>component_1</th>\n",
       "      <th>component_3</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>...</th>\n",
       "      <th>vas_id_5</th>\n",
       "      <th>vas_id_6</th>\n",
       "      <th>vas_id_7</th>\n",
       "      <th>vas_id_8</th>\n",
       "      <th>vas_id_9</th>\n",
       "      <th>vas_id_ord</th>\n",
       "      <th>vas_id_date_dif_1</th>\n",
       "      <th>vas_id_date_dif_2</th>\n",
       "      <th>vas_id_mean</th>\n",
       "      <th>log_vas_id_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.164683</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.069795</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010239</td>\n",
       "      <td>0.070406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.536963</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.069795</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.674328</td>\n",
       "      <td>0.885016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   target        id  buy_time_train  vas_id  time_delta  component_1  \\\n",
       "0     1.0  0.164683            0.28   0.125        0.16     0.000067   \n",
       "1     0.0  0.536963            0.92   0.375        0.44     0.000067   \n",
       "\n",
       "   component_3  month   day  weekofyear  ...  vas_id_5  vas_id_6  vas_id_7  \\\n",
       "0     0.069795    0.2  0.28        0.28  ...       0.0       0.0       0.0   \n",
       "1     0.069795    1.0  0.92        0.92  ...       0.0       0.0       0.0   \n",
       "\n",
       "   vas_id_8  vas_id_9  vas_id_ord  vas_id_date_dif_1  vas_id_date_dif_2  \\\n",
       "0       0.0       0.0         0.0                0.0                0.0   \n",
       "1       0.0       0.0         0.0                0.0                0.0   \n",
       "\n",
       "   vas_id_mean  log_vas_id_mean  \n",
       "0     0.010239         0.070406  \n",
       "1     0.674328         0.885016  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.DataFrame(scaler.transform(test_data), columns=train_data_columns)\n",
    "test_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3d56b883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 99.14 MB\n",
      "Memory usage after optimization is: 49.57 MB\n",
      "Decreased by 50.0%\n",
      "Memory usage of dataframe is 23.39 MB\n",
      "Memory usage after optimization is: 11.69 MB\n",
      "Decreased by 50.0%\n"
     ]
    }
   ],
   "source": [
    "train_data = reduce_mem_usage(train_data)\n",
    "test_data = reduce_mem_usage(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "827000b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>buy_time_train</th>\n",
       "      <th>vas_id</th>\n",
       "      <th>time_delta</th>\n",
       "      <th>component_1</th>\n",
       "      <th>component_3</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>...</th>\n",
       "      <th>vas_id_5</th>\n",
       "      <th>vas_id_6</th>\n",
       "      <th>vas_id_7</th>\n",
       "      <th>vas_id_8</th>\n",
       "      <th>vas_id_9</th>\n",
       "      <th>vas_id_ord</th>\n",
       "      <th>vas_id_date_dif_1</th>\n",
       "      <th>vas_id_date_dif_2</th>\n",
       "      <th>vas_id_mean</th>\n",
       "      <th>log_vas_id_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accept</td>\n",
       "      <td>0.164683</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.069795</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010239</td>\n",
       "      <td>0.070406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>reject</td>\n",
       "      <td>0.536963</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.069795</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.674328</td>\n",
       "      <td>0.885016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   target        id  buy_time_train  vas_id  time_delta  component_1  \\\n",
       "0  accept  0.164683            0.28   0.125        0.16     0.000067   \n",
       "1  reject  0.536963            0.92   0.375        0.44     0.000067   \n",
       "\n",
       "   component_3  month   day  weekofyear  ...  vas_id_5  vas_id_6  vas_id_7  \\\n",
       "0     0.069795    0.2  0.28        0.28  ...       0.0       0.0       0.0   \n",
       "1     0.069795    1.0  0.92        0.92  ...       0.0       0.0       0.0   \n",
       "\n",
       "   vas_id_8  vas_id_9  vas_id_ord  vas_id_date_dif_1  vas_id_date_dif_2  \\\n",
       "0       0.0       0.0         0.0                0.0                0.0   \n",
       "1       0.0       0.0         0.0                0.0                0.0   \n",
       "\n",
       "   vas_id_mean  log_vas_id_mean  \n",
       "0     0.010239         0.070406  \n",
       "1     0.674328         0.885016  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = test_data.astype('float32')\n",
    "test_data.target = test_data.target.map(\n",
    "    {1.0:'accept', 0.0: 'reject'}\n",
    ")\n",
    "test_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e8cdbed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['target',\n",
       " 'id',\n",
       " 'buy_time_train',\n",
       " 'vas_id',\n",
       " 'time_delta',\n",
       " 'component_1',\n",
       " 'component_3',\n",
       " 'month',\n",
       " 'day',\n",
       " 'weekofyear',\n",
       " 'how_old',\n",
       " 'novelty',\n",
       " 'vas_id_1',\n",
       " 'vas_id_2',\n",
       " 'vas_id_4',\n",
       " 'vas_id_5',\n",
       " 'vas_id_6',\n",
       " 'vas_id_7',\n",
       " 'vas_id_8',\n",
       " 'vas_id_9',\n",
       " 'vas_id_ord',\n",
       " 'vas_id_date_dif_1',\n",
       " 'vas_id_date_dif_2',\n",
       " 'vas_id_mean',\n",
       " 'log_vas_id_mean']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_data.astype('float32')\n",
    "train_data.target = train_data.target.map(\n",
    "    {1:'accept', 0: 'reject'}\n",
    ")\n",
    "train_data.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c65e24bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_HEADER = ['target', 'id', 'buy_time_train', 'vas_id', 'time_delta', 'component_1', 'component_3',\n",
    " 'month', 'day', 'weekofyear', 'how_old', 'novelty', 'vas_id_1', 'vas_id_2', 'vas_id_4', 'vas_id_5',\n",
    " 'vas_id_6', 'vas_id_7', 'vas_id_8', 'vas_id_9', 'vas_id_ord', 'vas_id_date_dif_1', 'vas_id_date_dif_2',\n",
    " 'vas_id_mean', 'log_vas_id_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7d022062",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_FEATURE_NAMES = [\"vas_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "18c5b90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[CATEGORICAL_FEATURE_NAMES] = train_data[CATEGORICAL_FEATURE_NAMES].astype('str')\n",
    "test_data[CATEGORICAL_FEATURE_NAMES] = test_data[CATEGORICAL_FEATURE_NAMES].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1571cd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of the numerical feature names.\n",
    "NUMERIC_FEATURE_NAMES = [\n",
    "    'id', 'time_delta', 'component_1', 'component_3', 'month', 'day', \n",
    "    'weekofyear', 'how_old', 'novelty', 'vas_id_1', 'vas_id_2', 'vas_id_4', 'vas_id_5',\n",
    "    'vas_id_6', 'vas_id_7', 'vas_id_8', 'vas_id_9', 'vas_id_ord', 'vas_id_date_dif_1', \n",
    "    'vas_id_date_dif_2', 'vas_id_mean', 'log_vas_id_mean'\n",
    "]\n",
    "# A dictionary of the categorical features and their vocabulary.\n",
    "CATEGORICAL_FEATURES_WITH_VOCABULARY = {\n",
    "    \"vas_id\": sorted(list(train_data[\"vas_id\"].unique()))\n",
    "}\n",
    "# Name of the column to be used as instances weight.\n",
    "WEIGHT_COLUMN_NAME = \"buy_time_train\"\n",
    "# A list of the categorical feature names.\n",
    "#CATEGORICAL_FEATURE_NAMES = list(CATEGORICAL_FEATURES_WITH_VOCABULARY.keys())\n",
    "# A list of all the input features.\n",
    "FEATURE_NAMES = NUMERIC_FEATURE_NAMES + CATEGORICAL_FEATURE_NAMES\n",
    "# A list of column default values for each feature.\n",
    "COLUMN_DEFAULTS = [\n",
    "    [0.0] if feature_name in NUMERIC_FEATURE_NAMES + [WEIGHT_COLUMN_NAME] else [\"NA\"]\n",
    "    for feature_name in CSV_HEADER\n",
    "]\n",
    "# The name of the target feature.\n",
    "TARGET_FEATURE_NAME = \"target\"\n",
    "# A list of the labels of the target features.\n",
    "TARGET_LABELS = [\"reject\", \"accept\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ae7862b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_file = \"train_data.csv\"\n",
    "test_data_file = \"test_data.csv\"\n",
    "\n",
    "train_data.to_csv(train_data_file, index=False, header=False)\n",
    "test_data.to_csv(test_data_file, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f183dfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "WEIGHT_DECAY = 0.0001\n",
    "DROPOUT_RATE = 0.2\n",
    "BATCH_SIZE = 265\n",
    "NUM_EPOCHS = 15\n",
    "\n",
    "NUM_TRANSFORMER_BLOCKS = 3  # Number of transformer blocks.\n",
    "NUM_HEADS = 4  # Number of attention heads.\n",
    "EMBEDDING_DIMS = 16  # Embedding dimensions of the categorical features.\n",
    "MLP_HIDDEN_UNITS_FACTORS = [\n",
    "    2,\n",
    "    1,\n",
    "]  # MLP hidden layer units, as factors of the number of inputs.\n",
    "NUM_MLP_BLOCKS = 2  # Number of MLP blocks in the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d8c07faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_label_lookup = layers.StringLookup(\n",
    "    vocabulary=TARGET_LABELS, mask_token=None, num_oov_indices=0\n",
    ")\n",
    "\n",
    "\n",
    "def prepare_example(features, target):\n",
    "    target_index = target_label_lookup(target)\n",
    "    weights = features.pop(WEIGHT_COLUMN_NAME)\n",
    "    return features, target_index, weights\n",
    "\n",
    "\n",
    "def get_dataset_from_csv(csv_file_path, batch_size=128, shuffle=False):\n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "        csv_file_path,\n",
    "        batch_size=batch_size,\n",
    "        column_names=CSV_HEADER,\n",
    "        column_defaults=COLUMN_DEFAULTS,\n",
    "        label_name=TARGET_FEATURE_NAME,\n",
    "        num_epochs=1,\n",
    "        header=False,\n",
    "        na_value=\"?\",\n",
    "        shuffle=shuffle,\n",
    "    ).map(prepare_example, num_parallel_calls=tf.data.AUTOTUNE, deterministic=False)\n",
    "    return dataset.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "73b60e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(\n",
    "    model,\n",
    "    train_data_file,\n",
    "    test_data_file,\n",
    "    num_epochs,\n",
    "    learning_rate,\n",
    "    weight_decay,\n",
    "    batch_size,\n",
    "):\n",
    "\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=keras.losses.BinaryCrossentropy(),\n",
    "        metrics=[keras.metrics.BinaryAccuracy(name=\"accuracy\")],\n",
    "    )\n",
    "\n",
    "    train_dataset = get_dataset_from_csv(train_data_file, batch_size, shuffle=True)\n",
    "    validation_dataset = get_dataset_from_csv(test_data_file, batch_size)\n",
    "\n",
    "\n",
    "\n",
    "    model_checkpoint = callbacks.ModelCheckpoint(filepath='model_best_{epoch}',\n",
    "                                   monitor='val_loss',\n",
    "                                   verbose=1,\n",
    "                                   save_best_only=True,\n",
    "                                   save_weights_only=False,\n",
    "                                   mode='auto') #,\n",
    "                                   #save_freq=20)\n",
    "\n",
    "    \n",
    "\n",
    "    reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_accuracy',\n",
    "                                        factor=0.1,\n",
    "                                        patience=0,\n",
    "                                        verbose=1,\n",
    "                                        mode='auto',\n",
    "                                        min_delta=0.001,\n",
    "                                        cooldown=0,\n",
    "                                        min_lr=1e-10)\n",
    "    \n",
    "    early_stop = callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                     min_delta=0.001,\n",
    "                                     patience=15,\n",
    "                                     verbose=1,\n",
    "                                     mode='auto',\n",
    "                                     baseline=None,\n",
    "                                     restore_best_weights=False)\n",
    "\n",
    "    print(\"Start training the model...\")\n",
    "    history = model.fit(\n",
    "        train_dataset, epochs=num_epochs, validation_data=validation_dataset,\n",
    "        callbacks=[model_checkpoint, early_stop]\n",
    "    )\n",
    "    print(\"Model training finished\")\n",
    "\n",
    "    _, accuracy = model.evaluate(validation_dataset, verbose=0)\n",
    "\n",
    "    print(f\"Validation accuracy: {round(accuracy * 100, 2)}%\")\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5c507bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_inputs():\n",
    "    inputs = {}\n",
    "    for feature_name in FEATURE_NAMES:\n",
    "        if feature_name in NUMERIC_FEATURE_NAMES:\n",
    "            inputs[feature_name] = layers.Input(\n",
    "                name=feature_name, shape=(), dtype=tf.float32\n",
    "            )\n",
    "        else:\n",
    "            inputs[feature_name] = layers.Input(\n",
    "                name=feature_name, shape=(), dtype=tf.string\n",
    "            )\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b4b29284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_inputs(inputs, embedding_dims):\n",
    "\n",
    "    encoded_categorical_feature_list = []\n",
    "    numerical_feature_list = []\n",
    "\n",
    "    for feature_name in inputs:\n",
    "        if feature_name in CATEGORICAL_FEATURE_NAMES:\n",
    "\n",
    "            # Get the vocabulary of the categorical feature.\n",
    "            vocabulary = CATEGORICAL_FEATURES_WITH_VOCABULARY[feature_name]\n",
    "\n",
    "            # Create a lookup to convert string values to an integer indices.\n",
    "            # Since we are not using a mask token nor expecting any out of vocabulary\n",
    "            # (oov) token, we set mask_token to None and  num_oov_indices to 0.\n",
    "            lookup = layers.StringLookup(\n",
    "                vocabulary=vocabulary,\n",
    "                mask_token=None,\n",
    "                num_oov_indices=0,\n",
    "                output_mode=\"int\",\n",
    "            )\n",
    "\n",
    "            # Convert the string input values into integer indices.\n",
    "            encoded_feature = lookup(inputs[feature_name])\n",
    "\n",
    "            # Create an embedding layer with the specified dimensions.\n",
    "            embedding = layers.Embedding(\n",
    "                input_dim=len(vocabulary), output_dim=embedding_dims\n",
    "            )\n",
    "\n",
    "            # Convert the index values to embedding representations.\n",
    "            encoded_categorical_feature = embedding(encoded_feature)\n",
    "            encoded_categorical_feature_list.append(encoded_categorical_feature)\n",
    "\n",
    "        else:\n",
    "\n",
    "            # Use the numerical features as-is.\n",
    "            numerical_feature = tf.expand_dims(inputs[feature_name], -1)\n",
    "            numerical_feature_list.append(numerical_feature)\n",
    "\n",
    "    return encoded_categorical_feature_list, numerical_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7a332269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp(hidden_units, dropout_rate, activation, normalization_layer, name=None):\n",
    "\n",
    "    mlp_layers = []\n",
    "    for units in hidden_units:\n",
    "        mlp_layers.append(normalization_layer),\n",
    "        mlp_layers.append(layers.Dense(units, activation=activation))\n",
    "        mlp_layers.append(layers.Dropout(dropout_rate))\n",
    "\n",
    "    return keras.Sequential(mlp_layers, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f114c2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline_model(\n",
    "    embedding_dims, num_mlp_blocks, mlp_hidden_units_factors, dropout_rate\n",
    "):\n",
    "\n",
    "    # Create model inputs.\n",
    "    inputs = create_model_inputs()\n",
    "    # encode features.\n",
    "    encoded_categorical_feature_list, numerical_feature_list = encode_inputs(\n",
    "        inputs, embedding_dims\n",
    "    )\n",
    "    # Concatenate all features.\n",
    "    features = layers.concatenate(\n",
    "        encoded_categorical_feature_list + numerical_feature_list\n",
    "    )\n",
    "    # Compute Feedforward layer units.\n",
    "    feedforward_units = [features.shape[-1]]\n",
    "\n",
    "    # Create several feedforwad layers with skip connections.\n",
    "    for layer_idx in range(num_mlp_blocks):\n",
    "        features = create_mlp(\n",
    "            hidden_units=feedforward_units,\n",
    "            dropout_rate=dropout_rate,\n",
    "            activation=keras.activations.gelu,\n",
    "            normalization_layer=layers.LayerNormalization(epsilon=1e-6),\n",
    "            name=f\"feedforward_{layer_idx}\",\n",
    "        )(features)\n",
    "\n",
    "    # Compute MLP hidden_units.\n",
    "    mlp_hidden_units = [\n",
    "        factor * features.shape[-1] for factor in mlp_hidden_units_factors\n",
    "    ]\n",
    "    # Create final MLP.\n",
    "    features = create_mlp(\n",
    "        hidden_units=mlp_hidden_units,\n",
    "        dropout_rate=dropout_rate,\n",
    "        activation=keras.activations.selu,\n",
    "        normalization_layer=layers.BatchNormalization(),\n",
    "        name=\"MLP\",\n",
    "    )(features)\n",
    "\n",
    "    # Add a sigmoid as a binary classifer.\n",
    "    outputs = layers.Dense(units=1, activation=\"sigmoid\", name=\"sigmoid\")(features)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "79a73375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total model weights: 9325\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "baseline_model = create_baseline_model(\n",
    "    embedding_dims=EMBEDDING_DIMS,\n",
    "    num_mlp_blocks=NUM_MLP_BLOCKS,\n",
    "    mlp_hidden_units_factors=MLP_HIDDEN_UNITS_FACTORS,\n",
    "    dropout_rate=DROPOUT_RATE,\n",
    ")\n",
    "\n",
    "print(\"Total model weights:\", baseline_model.count_params())\n",
    "keras.utils.plot_model(baseline_model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2b816c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/30\n",
      "   1962/Unknown - 35s 17ms/step - loss: 0.1912 - accuracy: 0.9040WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.20290, saving model to model_best_1\n",
      "INFO:tensorflow:Assets written to: model_best_1/assets\n",
      "1962/1962 [==============================] - 44s 21ms/step - loss: 0.1912 - accuracy: 0.9040 - val_loss: 0.2029 - val_accuracy: 0.8642\n",
      "Epoch 2/30\n",
      "1959/1962 [============================>.] - ETA: 0s - loss: 0.1911 - accuracy: 0.9040WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.20290\n",
      "1962/1962 [==============================] - 16s 8ms/step - loss: 0.1911 - accuracy: 0.9040 - val_loss: 0.2261 - val_accuracy: 0.8609\n",
      "Epoch 3/30\n",
      "1960/1962 [============================>.] - ETA: 0s - loss: 0.1912 - accuracy: 0.9040WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.20290\n",
      "1962/1962 [==============================] - 17s 9ms/step - loss: 0.1912 - accuracy: 0.9040 - val_loss: 0.2247 - val_accuracy: 0.8619\n",
      "Epoch 4/30\n",
      "1961/1962 [============================>.] - ETA: 0s - loss: 0.1913 - accuracy: 0.9040WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.20290\n",
      "1962/1962 [==============================] - 17s 9ms/step - loss: 0.1913 - accuracy: 0.9040 - val_loss: 0.2086 - val_accuracy: 0.8639\n",
      "Epoch 5/30\n",
      "1957/1962 [============================>.] - ETA: 0s - loss: 0.1913 - accuracy: 0.9040WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.20290\n",
      "1962/1962 [==============================] - 17s 9ms/step - loss: 0.1914 - accuracy: 0.9040 - val_loss: 0.2041 - val_accuracy: 0.8636\n",
      "Epoch 6/30\n",
      "1957/1962 [============================>.] - ETA: 0s - loss: 0.1911 - accuracy: 0.9041WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.20290\n",
      "1962/1962 [==============================] - 17s 9ms/step - loss: 0.1912 - accuracy: 0.9041 - val_loss: 0.2265 - val_accuracy: 0.8623\n",
      "Epoch 7/30\n",
      "1956/1962 [============================>.] - ETA: 0s - loss: 0.1911 - accuracy: 0.9042WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.20290\n",
      "1962/1962 [==============================] - 17s 9ms/step - loss: 0.1911 - accuracy: 0.9041 - val_loss: 0.2240 - val_accuracy: 0.8620\n",
      "Epoch 8/30\n",
      "1960/1962 [============================>.] - ETA: 0s - loss: 0.1915 - accuracy: 0.9039WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.20290\n",
      "1962/1962 [==============================] - 17s 9ms/step - loss: 0.1915 - accuracy: 0.9039 - val_loss: 0.2291 - val_accuracy: 0.8614\n",
      "Epoch 9/30\n",
      "1960/1962 [============================>.] - ETA: 0s - loss: 0.1912 - accuracy: 0.9040WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.20290\n",
      "1962/1962 [==============================] - 17s 9ms/step - loss: 0.1912 - accuracy: 0.9040 - val_loss: 0.2200 - val_accuracy: 0.8623\n",
      "Epoch 10/30\n",
      "1961/1962 [============================>.] - ETA: 0s - loss: 0.1914 - accuracy: 0.9042WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.20290\n",
      "1962/1962 [==============================] - 17s 9ms/step - loss: 0.1914 - accuracy: 0.9042 - val_loss: 0.2309 - val_accuracy: 0.8619\n",
      "Epoch 11/30\n",
      "1957/1962 [============================>.] - ETA: 0s - loss: 0.1914 - accuracy: 0.9041WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.20290\n",
      "1962/1962 [==============================] - 17s 9ms/step - loss: 0.1914 - accuracy: 0.9041 - val_loss: 0.2112 - val_accuracy: 0.8639\n",
      "Epoch 12/30\n",
      "1957/1962 [============================>.] - ETA: 0s - loss: 0.1912 - accuracy: 0.9041WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.20290\n",
      "1962/1962 [==============================] - 18s 9ms/step - loss: 0.1912 - accuracy: 0.9041 - val_loss: 0.2222 - val_accuracy: 0.8626\n",
      "Epoch 13/30\n",
      "1958/1962 [============================>.] - ETA: 0s - loss: 0.1913 - accuracy: 0.9040WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.20290\n",
      "1962/1962 [==============================] - 17s 9ms/step - loss: 0.1913 - accuracy: 0.9040 - val_loss: 0.2302 - val_accuracy: 0.8615\n",
      "Epoch 14/30\n",
      "1962/1962 [==============================] - ETA: 0s - loss: 0.1912 - accuracy: 0.9040WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.20290\n",
      "1962/1962 [==============================] - 17s 9ms/step - loss: 0.1912 - accuracy: 0.9040 - val_loss: 0.2257 - val_accuracy: 0.8613\n",
      "Epoch 15/30\n",
      "1960/1962 [============================>.] - ETA: 0s - loss: 0.1913 - accuracy: 0.9040WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15: val_loss did not improve from 0.20290\n",
      "1962/1962 [==============================] - 17s 9ms/step - loss: 0.1913 - accuracy: 0.9040 - val_loss: 0.2250 - val_accuracy: 0.8632\n",
      "Epoch 16/30\n",
      "1957/1962 [============================>.] - ETA: 0s - loss: 0.1912 - accuracy: 0.9040WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.20290\n",
      "1962/1962 [==============================] - 18s 9ms/step - loss: 0.1913 - accuracy: 0.9040 - val_loss: 0.2421 - val_accuracy: 0.8599\n",
      "Epoch 16: early stopping\n",
      "Model training finished\n",
      "WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "Validation accuracy: 85.99%\n"
     ]
    }
   ],
   "source": [
    "history = run_experiment(\n",
    "    model=baseline_model,\n",
    "    train_data_file=train_data_file,\n",
    "    test_data_file=test_data_file,\n",
    "    num_epochs=30,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7880ff49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "92ed2790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "958/958 [==============================] - 6s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test = test_data['target']\n",
    "y_test = y_test.map(\n",
    "    {'accept': 1, 'reject': 0}\n",
    ")\n",
    "y_pred = baseline_model.predict(get_dataset_from_csv(test_data_file))\n",
    "y_pred = y_pred.reshape((-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "77307ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold : 0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.76      0.86    111491\n",
      "           1       0.29      0.97      0.45     11127\n",
      "\n",
      "    accuracy                           0.78    122618\n",
      "   macro avg       0.64      0.86      0.66    122618\n",
      "weighted avg       0.93      0.78      0.83    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.12758620689655173\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.81      0.90    111491\n",
      "           1       0.34      0.96      0.50     11127\n",
      "\n",
      "    accuracy                           0.83    122618\n",
      "   macro avg       0.67      0.89      0.70    122618\n",
      "weighted avg       0.94      0.83      0.86    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.15517241379310345\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.83      0.91    111491\n",
      "           1       0.37      0.95      0.53     11127\n",
      "\n",
      "    accuracy                           0.85    122618\n",
      "   macro avg       0.68      0.89      0.72    122618\n",
      "weighted avg       0.94      0.85      0.87    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.1827586206896552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.84      0.91    111491\n",
      "           1       0.37      0.95      0.53     11127\n",
      "\n",
      "    accuracy                           0.85    122618\n",
      "   macro avg       0.68      0.89      0.72    122618\n",
      "weighted avg       0.94      0.85      0.87    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.21034482758620693\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.84      0.91    111491\n",
      "           1       0.37      0.95      0.53     11127\n",
      "\n",
      "    accuracy                           0.85    122618\n",
      "   macro avg       0.68      0.90      0.72    122618\n",
      "weighted avg       0.94      0.85      0.88    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.23793103448275865\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.84      0.91    111491\n",
      "           1       0.38      0.95      0.54     11127\n",
      "\n",
      "    accuracy                           0.85    122618\n",
      "   macro avg       0.69      0.90      0.73    122618\n",
      "weighted avg       0.94      0.85      0.88    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.2655172413793104\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.91    111491\n",
      "           1       0.38      0.95      0.54     11127\n",
      "\n",
      "    accuracy                           0.85    122618\n",
      "   macro avg       0.69      0.90      0.73    122618\n",
      "weighted avg       0.94      0.85      0.88    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.2931034482758621\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.91    111491\n",
      "           1       0.38      0.95      0.55     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.73    122618\n",
      "weighted avg       0.94      0.86      0.88    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.3206896551724138\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.92    111491\n",
      "           1       0.38      0.95      0.55     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.73    122618\n",
      "weighted avg       0.94      0.86      0.88    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.34827586206896555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.92    111491\n",
      "           1       0.38      0.95      0.55     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.73    122618\n",
      "weighted avg       0.94      0.86      0.88    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.3758620689655173\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.92    111491\n",
      "           1       0.39      0.95      0.55     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.73    122618\n",
      "weighted avg       0.94      0.86      0.88    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.403448275862069\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.92    111491\n",
      "           1       0.39      0.95      0.55     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.73    122618\n",
      "weighted avg       0.94      0.86      0.88    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.4310344827586208\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.92    111491\n",
      "           1       0.39      0.95      0.55     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.73    122618\n",
      "weighted avg       0.94      0.86      0.88    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.45862068965517244\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.92    111491\n",
      "           1       0.39      0.95      0.55     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.73    122618\n",
      "weighted avg       0.94      0.86      0.88    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.4862068965517242\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.92    111491\n",
      "           1       0.39      0.95      0.55     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.73    122618\n",
      "weighted avg       0.94      0.86      0.88    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.5137931034482759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.92    111491\n",
      "           1       0.39      0.95      0.55     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.73    122618\n",
      "weighted avg       0.94      0.86      0.88    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.5413793103448277\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.92    111491\n",
      "           1       0.39      0.95      0.55     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.74    122618\n",
      "weighted avg       0.94      0.86      0.89    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.5689655172413793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.92    111491\n",
      "           1       0.39      0.95      0.56     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.74    122618\n",
      "weighted avg       0.94      0.86      0.89    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.5965517241379311\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.92    111491\n",
      "           1       0.39      0.95      0.56     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.74    122618\n",
      "weighted avg       0.94      0.86      0.89    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.6241379310344828\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.86      0.92    111491\n",
      "           1       0.39      0.95      0.56     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.74    122618\n",
      "weighted avg       0.94      0.86      0.89    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.6517241379310346\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.86      0.92    111491\n",
      "           1       0.40      0.95      0.56     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.74    122618\n",
      "weighted avg       0.94      0.86      0.89    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.6793103448275862\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.86      0.92    111491\n",
      "           1       0.40      0.94      0.56     11127\n",
      "\n",
      "    accuracy                           0.87    122618\n",
      "   macro avg       0.70      0.90      0.74    122618\n",
      "weighted avg       0.94      0.87      0.89    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.706896551724138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.86      0.92    111491\n",
      "           1       0.40      0.94      0.56     11127\n",
      "\n",
      "    accuracy                           0.87    122618\n",
      "   macro avg       0.70      0.90      0.74    122618\n",
      "weighted avg       0.94      0.87      0.89    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.7344827586206897\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.87      0.93    111491\n",
      "           1       0.41      0.92      0.57     11127\n",
      "\n",
      "    accuracy                           0.87    122618\n",
      "   macro avg       0.70      0.90      0.75    122618\n",
      "weighted avg       0.94      0.87      0.89    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.7620689655172415\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93    111491\n",
      "           1       0.42      0.91      0.58     11127\n",
      "\n",
      "    accuracy                           0.88    122618\n",
      "   macro avg       0.71      0.89      0.75    122618\n",
      "weighted avg       0.94      0.88      0.90    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.7896551724137931\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93    111491\n",
      "           1       0.43      0.89      0.58     11127\n",
      "\n",
      "    accuracy                           0.88    122618\n",
      "   macro avg       0.71      0.89      0.76    122618\n",
      "weighted avg       0.94      0.88      0.90    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.8172413793103449\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.94    111491\n",
      "           1       0.45      0.86      0.59     11127\n",
      "\n",
      "    accuracy                           0.89    122618\n",
      "   macro avg       0.72      0.88      0.76    122618\n",
      "weighted avg       0.94      0.89      0.91    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.8448275862068966\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94    111491\n",
      "           1       0.47      0.80      0.59     11127\n",
      "\n",
      "    accuracy                           0.90    122618\n",
      "   macro avg       0.73      0.86      0.77    122618\n",
      "weighted avg       0.93      0.90      0.91    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.8724137931034484\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95    111491\n",
      "           1       0.49      0.73      0.59     11127\n",
      "\n",
      "    accuracy                           0.91    122618\n",
      "   macro avg       0.73      0.83      0.77    122618\n",
      "weighted avg       0.93      0.91      0.92    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96    111491\n",
      "           1       0.56      0.51      0.53     11127\n",
      "\n",
      "    accuracy                           0.92    122618\n",
      "   macro avg       0.75      0.73      0.74    122618\n",
      "weighted avg       0.92      0.92      0.92    122618\n",
      "\n",
      "***************************\n"
     ]
    }
   ],
   "source": [
    "for i in np.linspace(0.1, 0.9, num=30):\n",
    "    print(f\"threshold : {i}\")\n",
    "    print(classification_report(y_test, (y_pred > i) * 1))\n",
    "    print('***************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b55c3292",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model=models.load_model(\"model_best_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0bb99021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "958/958 [==============================] - 6s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(get_dataset_from_csv(test_data_file))\n",
    "y_pred = y_pred.reshape((-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "dc57dde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold : 0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.82      0.90    111491\n",
      "           1       0.35      0.96      0.51     11127\n",
      "\n",
      "    accuracy                           0.83    122618\n",
      "   macro avg       0.67      0.89      0.70    122618\n",
      "weighted avg       0.94      0.83      0.86    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.12758620689655173\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.84      0.91    111491\n",
      "           1       0.37      0.95      0.53     11127\n",
      "\n",
      "    accuracy                           0.85    122618\n",
      "   macro avg       0.68      0.89      0.72    122618\n",
      "weighted avg       0.94      0.85      0.87    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.15517241379310345\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.84      0.91    111491\n",
      "           1       0.37      0.95      0.53     11127\n",
      "\n",
      "    accuracy                           0.85    122618\n",
      "   macro avg       0.68      0.90      0.72    122618\n",
      "weighted avg       0.94      0.85      0.88    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.1827586206896552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.84      0.91    111491\n",
      "           1       0.38      0.95      0.54     11127\n",
      "\n",
      "    accuracy                           0.85    122618\n",
      "   macro avg       0.69      0.90      0.73    122618\n",
      "weighted avg       0.94      0.85      0.88    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.21034482758620693\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.91    111491\n",
      "           1       0.38      0.95      0.54     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.73    122618\n",
      "weighted avg       0.94      0.86      0.88    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.23793103448275865\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.92    111491\n",
      "           1       0.39      0.95      0.55     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.73    122618\n",
      "weighted avg       0.94      0.86      0.88    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.2655172413793104\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.92    111491\n",
      "           1       0.39      0.95      0.55     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.73    122618\n",
      "weighted avg       0.94      0.86      0.88    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.2931034482758621\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.92    111491\n",
      "           1       0.39      0.95      0.55     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.73    122618\n",
      "weighted avg       0.94      0.86      0.88    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.3206896551724138\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.92    111491\n",
      "           1       0.39      0.95      0.55     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.74    122618\n",
      "weighted avg       0.94      0.86      0.88    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.34827586206896555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.92    111491\n",
      "           1       0.39      0.95      0.55     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.74    122618\n",
      "weighted avg       0.94      0.86      0.89    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.3758620689655173\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.92    111491\n",
      "           1       0.39      0.95      0.56     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.74    122618\n",
      "weighted avg       0.94      0.86      0.89    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.403448275862069\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.92    111491\n",
      "           1       0.39      0.95      0.56     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.74    122618\n",
      "weighted avg       0.94      0.86      0.89    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.4310344827586208\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.86      0.92    111491\n",
      "           1       0.40      0.95      0.56     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.74    122618\n",
      "weighted avg       0.94      0.86      0.89    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.45862068965517244\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.86      0.92    111491\n",
      "           1       0.40      0.95      0.56     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.74    122618\n",
      "weighted avg       0.94      0.86      0.89    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.4862068965517242\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.86      0.92    111491\n",
      "           1       0.40      0.95      0.56     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.74    122618\n",
      "weighted avg       0.94      0.86      0.89    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.5137931034482759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.86      0.92    111491\n",
      "           1       0.40      0.95      0.56     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.69      0.90      0.74    122618\n",
      "weighted avg       0.94      0.86      0.89    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.5413793103448277\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.86      0.92    111491\n",
      "           1       0.40      0.95      0.56     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.70      0.90      0.74    122618\n",
      "weighted avg       0.94      0.86      0.89    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.5689655172413793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.86      0.92    111491\n",
      "           1       0.40      0.94      0.56     11127\n",
      "\n",
      "    accuracy                           0.86    122618\n",
      "   macro avg       0.70      0.90      0.74    122618\n",
      "weighted avg       0.94      0.86      0.89    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.5965517241379311\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.86      0.92    111491\n",
      "           1       0.40      0.94      0.56     11127\n",
      "\n",
      "    accuracy                           0.87    122618\n",
      "   macro avg       0.70      0.90      0.74    122618\n",
      "weighted avg       0.94      0.87      0.89    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.6241379310344828\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.86      0.92    111491\n",
      "           1       0.40      0.94      0.56     11127\n",
      "\n",
      "    accuracy                           0.87    122618\n",
      "   macro avg       0.70      0.90      0.74    122618\n",
      "weighted avg       0.94      0.87      0.89    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.6517241379310346\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.86      0.92    111491\n",
      "           1       0.40      0.93      0.56     11127\n",
      "\n",
      "    accuracy                           0.87    122618\n",
      "   macro avg       0.70      0.90      0.74    122618\n",
      "weighted avg       0.94      0.87      0.89    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.6793103448275862\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.87      0.93    111491\n",
      "           1       0.41      0.92      0.57     11127\n",
      "\n",
      "    accuracy                           0.87    122618\n",
      "   macro avg       0.70      0.89      0.75    122618\n",
      "weighted avg       0.94      0.87      0.89    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.706896551724138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93    111491\n",
      "           1       0.42      0.91      0.58     11127\n",
      "\n",
      "    accuracy                           0.88    122618\n",
      "   macro avg       0.71      0.89      0.75    122618\n",
      "weighted avg       0.94      0.88      0.90    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.7344827586206897\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93    111491\n",
      "           1       0.43      0.89      0.58     11127\n",
      "\n",
      "    accuracy                           0.88    122618\n",
      "   macro avg       0.71      0.89      0.76    122618\n",
      "weighted avg       0.94      0.88      0.90    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.7620689655172415\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94    111491\n",
      "           1       0.45      0.86      0.59     11127\n",
      "\n",
      "    accuracy                           0.89    122618\n",
      "   macro avg       0.72      0.88      0.76    122618\n",
      "weighted avg       0.94      0.89      0.91    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.7896551724137931\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94    111491\n",
      "           1       0.47      0.81      0.60     11127\n",
      "\n",
      "    accuracy                           0.90    122618\n",
      "   macro avg       0.73      0.86      0.77    122618\n",
      "weighted avg       0.93      0.90      0.91    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.8172413793103449\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95    111491\n",
      "           1       0.51      0.71      0.59     11127\n",
      "\n",
      "    accuracy                           0.91    122618\n",
      "   macro avg       0.74      0.82      0.77    122618\n",
      "weighted avg       0.93      0.91      0.92    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.8448275862068966\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96    111491\n",
      "           1       0.55      0.59      0.57     11127\n",
      "\n",
      "    accuracy                           0.92    122618\n",
      "   macro avg       0.75      0.77      0.76    122618\n",
      "weighted avg       0.92      0.92      0.92    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.8724137931034484\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96    111491\n",
      "           1       0.62      0.41      0.50     11127\n",
      "\n",
      "    accuracy                           0.92    122618\n",
      "   macro avg       0.78      0.69      0.73    122618\n",
      "weighted avg       0.91      0.92      0.92    122618\n",
      "\n",
      "***************************\n",
      "threshold : 0.9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96    111491\n",
      "           1       0.73      0.28      0.40     11127\n",
      "\n",
      "    accuracy                           0.93    122618\n",
      "   macro avg       0.83      0.63      0.68    122618\n",
      "weighted avg       0.91      0.93      0.91    122618\n",
      "\n",
      "***************************\n"
     ]
    }
   ],
   "source": [
    "for i in np.linspace(0.1, 0.9, num=30):\n",
    "    print(f\"threshold : {i}\")\n",
    "    print(classification_report(y_test, (y_pred > i) * 1))\n",
    "    print('***************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fcf666",
   "metadata": {},
   "source": [
    "Бог любит троицу. 3 лучшие модели показали одни и те же метрики. Скорее всего, если это даже и локальный, но очень значимый для этого датасета минимум. Но LGB переобучен, у нейронной сети тоже есть небольшое переобучение, а Катбуст дает одинаковые метрики на трейне и тесте. Кроме того, он проще и легче чем нейронка. Но шеф сказал использовать нейронку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1b93ad15",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f877a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
